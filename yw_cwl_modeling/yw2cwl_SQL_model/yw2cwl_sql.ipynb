{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import sqlite3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yw_model_file = \"example_sql/paleocar_models/paleocar_models.P\"\n",
    "\n",
    "db_model = yw_model_file[:-2] + '.db'\n",
    "#print(db_model)\n",
    "conn = sqlite3.connect(db_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for parsing the yw models file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### function extracting the programs.\n",
    "\n",
    "def extract_steps(line):\n",
    "    \n",
    "    #% FACT: program(program_id, program_name, qualified_program_name, begin_annotation_id, end_annotation_id).\n",
    "    #print(\"Extracting steps.\")\n",
    "    ## Extract data between \"(\" and \")\".\n",
    "    data = line[line.index(\"(\")+1:line.index(\")\")]\n",
    "    \n",
    "    data = data.split(',')\n",
    "    #print(data)\n",
    "    \n",
    "    \n",
    "    ins_query = [data[0].strip().strip(\"'\"),data[1].strip().strip(\"'\"),data[2].strip().strip(\"'\")]\n",
    "    conn.execute(\"\"\"insert into steps values(?,?,?)\"\"\", ins_query)\n",
    "    conn.commit()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### function extracting the workflow.\n",
    "\n",
    "def extract_workflows(line):\n",
    "    \n",
    "    #print(line)\n",
    "    data = line[line.index(\"(\")+1:line.index(\")\")]\n",
    "    number = ''.join(data)\n",
    "    \n",
    "    conn.execute(\"\"\"insert into workflow values(?)\"\"\",[number])\n",
    "    conn.commit()\n",
    "      \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### function extracting the ports\n",
    "\n",
    "def extract_ports(line):\n",
    "    #print(\"Extracting ports.\")\n",
    "    ## Extract data between \"(\" and \")\".\n",
    "    data = line[line.index(\"(\")+1:line.index(\")\")]\n",
    "    \n",
    "    #% FACT: port(port_id, port_type, port_name, qualified_port_name, port_annotation_id, data_id).\n",
    "    \n",
    "    data = data.split(',')\n",
    "    \n",
    "    if data[1].strip().strip(\"'\").upper().strip('\"') == 'PARAM':\n",
    "        port_type = 'IN'\n",
    "    else:\n",
    "        port_type = data[1].strip().strip(\"'\").upper().strip('\"')\n",
    "    \n",
    "    ins_query = [data[0].strip().strip(\"'\"),port_type,data[2].strip().strip(\"'\"),data[3].strip().strip(\"'\")\n",
    "                 ,data[4].strip().strip(\"'\"),data[5].strip().strip(\"'\")]\n",
    "    conn.execute(\"\"\"insert into port values(?,?,?,?,?,?)\"\"\", ins_query)\n",
    "    conn.commit()\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### function extracting the input ports\n",
    "\n",
    "def input_ports(line):\n",
    "    #print(\"Extracting Input ports.\")\n",
    "    \n",
    "    ## Extract data between \"(\" and \")\".\n",
    "    ## % FACT: has_in_port(step_id, port_id).\n",
    "\n",
    "    data = line[line.index(\"(\")+1:line.index(\")\")]\n",
    "    \n",
    "    data = data.split(',')\n",
    "    ins_query = [data[0].strip().strip(\"'\").strip('\"'),data[1].strip().strip(\"'\").strip('\"')]\n",
    "    conn.execute(\"\"\"insert into has_in_port values(?,?)\"\"\", ins_query)\n",
    "    conn.commit()\n",
    "    \n",
    "    #in_ports[data[0]].append((data[0].strip(), data[1].strip()))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### function extracting the output ports \n",
    "\n",
    "def output_ports(line): \n",
    "    #print(\"Extracting output ports.\")\n",
    "    ## Extract data between \"(\" and \")\".\n",
    "    data = line[line.index(\"(\")+1:line.index(\")\")]\n",
    "    data = data.split(',')\n",
    "    ins_query = [data[0].strip().strip(\"'\").strip('\"'),data[1].strip().strip(\"'\").strip('\"')]\n",
    "    conn.execute(\"\"\"insert into has_out_port values(?,?)\"\"\", ins_query)\n",
    "    conn.commit()\n",
    "    #out_ports[data[0]].append((data[0].strip(), data[1].strip()))\n",
    "    #print(data)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### function extracting the subprograms \n",
    "\n",
    "def has_subprogram(line): \n",
    "    #print(\"Extracting output ports.\")\n",
    "    ## Extract data between \"(\" and \")\".\n",
    "    data = line[line.index(\"(\")+1:line.index(\")\")]\n",
    "    data = data.split(',')\n",
    "    \n",
    "    ins_query = [data[0].strip().strip(\"'\").strip('\"'),data[1].strip().strip(\"'\").strip('\"')]\n",
    "    conn.execute(\"\"\"insert into has_subprogram values(?,?)\"\"\", ins_query)\n",
    "    conn.commit()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### function extracting the output ports \n",
    "\n",
    "def get_port_connects_to_channel(line): \n",
    "     \n",
    "    data = line[line.index(\"(\")+1 : line.index(\")\")]\n",
    "    data = data.split(',')\n",
    "\n",
    "    ins_query = [data[0].strip().strip(\"'\"),data[1].strip().strip(\"'\")]\n",
    "    conn.execute(\"\"\"insert into port_connects_to_channel values(?,?)\"\"\", ins_query)\n",
    "    conn.commit()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_inflow_connections(line): \n",
    "     \n",
    "    #print(line)\n",
    "    data = line[line.index(\"(\")+1:line.index(\")\")]\n",
    "    data = data.split(',')\n",
    "    #inflow_conn[data[0]]= data[1].strip()\n",
    "    \n",
    "    ins_query = [data[0].strip().strip(\"'\").strip('\"'),data[1].strip().strip(\"'\").strip('\"')]\n",
    "    conn.execute(\"\"\"insert into inflow_connects_to_channel values(?,?)\"\"\", ins_query)\n",
    "    conn.commit()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_outflow_connections(line): \n",
    "    #print(\"Extracting output ports.\")\n",
    "    ## Extract data between \"(\" and \")\".\n",
    "    data = line[line.index(\"(\")+1:line.index(\")\")]\n",
    "    data = data.split(',')\n",
    "    #outflow_conn[data[0]]= data[1].strip()\n",
    "\n",
    "    ins_query = [data[0].strip().strip(\"'\").strip('\"'),data[1].strip().strip(\"'\").strip('\"')]\n",
    "    conn.execute(\"\"\"insert into outflow_connects_to_channel values(?,?)\"\"\", ins_query)\n",
    "    conn.commit()\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### function extracting the output ports \n",
    "\n",
    "def get_port_data(line): \n",
    "    #print(\"Extracting output ports.\")\n",
    "    ## Extract data between \"(\" and \")\".\n",
    "    data = line[line.index(\"(\")+1:line.index(\")\")]\n",
    "    data = data.split(',')\n",
    "    \n",
    "    ins_query = [data[0].strip().strip(\"'\"),data[1].strip().strip(\"'\"),data[2].strip().strip(\"'\")]\n",
    "    conn.execute(\"\"\"insert into data values(?,?,?)\"\"\", ins_query)\n",
    "    conn.commit()\n",
    "    #print(data)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### function extracting the output ports \n",
    "\n",
    "def get_channel(line): \n",
    "    #print(\"Extracting output ports.\")\n",
    "    ## Extract data between \"(\" and \")\".\n",
    "    data = line[line.index(\"(\")+1:line.index(\")\")]\n",
    "    data = data.split(',')\n",
    "    \n",
    "    ins_query = [data[0].strip().strip(\"'\").strip('\"'),data[1].strip().strip(\"'\").strip('\"')]\n",
    "    conn.execute(\"\"\"insert into channel values(?,?)\"\"\", ins_query)\n",
    "    conn.commit()\n",
    "    #channel[data[0]]= data[1].strip()\n",
    "    #print(data)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### function extracting the port alias\n",
    "\n",
    "def port_alias(line):\n",
    "    data = line[line.index(\"(\")+1:line.index(\")\")]\n",
    "    data = data.split(',')\n",
    "    \n",
    "    port_id = data[0].strip()\n",
    "    alias = data[1].strip().strip(\"'\")\n",
    "    \n",
    "    #print(port_name, port_id,qualified_name)\n",
    "    \n",
    "    ins_query = [data[0].strip().strip(\"'\").strip('\"'),data[1].strip().strip(\"'\").strip('\"')]\n",
    "    conn.execute(\"\"\"insert into port_alias values(?,?)\"\"\", ins_query)\n",
    "    conn.commit()\n",
    "    \n",
    "    '''\n",
    "    ### regex for splitting the string and getting qualified program name\n",
    "    regex = re.compile(r'>|<')\n",
    "    qname = regex.split(qualified_name)\n",
    "    \n",
    "    pname = qname[0].split('.')[-1] \n",
    "    \n",
    "    if pname.find('-') > -1:\n",
    "        port_alt_name[alias] = pname[:-1]+ '/' +port_name\n",
    "    else:\n",
    "        port_alt_name[alias] = pname + '/' +port_name\n",
    "       \n",
    "    '''\n",
    "    return \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_yw_model(filename):\n",
    "    regex = re.compile(r'^%')\n",
    "    chk_channel = re.compile(r'^ch')\n",
    "    with open(filename, \"r\") as yw_struct:\n",
    "        line = yw_struct.readline()\n",
    "        while line:\n",
    "            #print(line)\n",
    "            comments = regex.match(line)\n",
    "            if comments: \n",
    "                #print(line)\n",
    "                line = yw_struct.readline()\n",
    "            else:  \n",
    "                if(\"program(\" in line and \"has_subprogram\" not in line):\n",
    "                    extract_steps(line)\n",
    "                elif(\"workflow(\" in line):\n",
    "                    extract_workflows(line)            \n",
    "                elif(\"has_subprogram(\" in line):\n",
    "                    has_subprogram(line)            \n",
    "                elif(\"port(\" in line  and \"has_in_port(\" not in line and \"has_out_port\" not in line):\n",
    "                #    print(line)\n",
    "                    extract_ports(line)\n",
    "                elif(\"has_in_port(\" in line):\n",
    "                    input_ports(line)\n",
    "                elif(\"has_out_port(\" in line ):\n",
    "                    output_ports(line)\n",
    "                elif (\"port_alias(\" in line ): \n",
    "                    port_alias(line)\n",
    "                elif(\"data(\" in line):\n",
    "                    get_port_data(line)\n",
    "                elif(\"port_connects_to_channel(\" in line):\n",
    "                    #print(line)\n",
    "                    get_port_connects_to_channel(line)\n",
    "                elif(\"inflow_connects_to_channel(\"in line):\n",
    "                    #print(line)\n",
    "                    get_inflow_connections(line)                    \n",
    "                elif(\"outflow_connects_to_channel(\"in line):\n",
    "                    get_outflow_connections(line)\n",
    "                elif( chk_channel.match(line) ):\n",
    "                    get_channel(line)\n",
    "\n",
    "                line = yw_struct.readline()\n",
    "        \n",
    "        #get_in_out_ports()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()\n",
    "conn.execute (''' drop table if exists channel ''')                    \n",
    "conn.execute (''' drop table if exists data  ''')                 \n",
    "conn.execute (''' drop table if exists has_in_port ''')                  \n",
    "conn.execute (''' drop table if exists has_out_port ''')                \n",
    "conn.execute (''' drop table if exists has_subprogram ''')              \n",
    "conn.execute (''' drop table if exists inflow_connects_to_channel ''')  \n",
    "conn.execute (''' drop table if exists outflow_connects_to_channel ''')\n",
    "conn.execute (''' drop table if exists port ''')\n",
    "conn.execute (''' drop table if exists port_alias ''')\n",
    "conn.execute (''' drop table if exists port_connects_to_channel ''')\n",
    "conn.execute (''' drop table if exists steps ''')\n",
    "conn.execute (''' drop table if exists workflow ''')\n",
    "conn.execute (''' drop table if exists cwl_steps_info ''')\n",
    "conn.execute (''' drop table if exists wf_ports ''')\n",
    "conn.execute (''' drop table if exists qual_portname ''')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1079bff80>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create tables for storing the data model. \n",
    "\n",
    "\n",
    "\n",
    "# % FACT: program(program_id, program_name, qualified_program_name, begin_annotation_id, end_annotation_id).\n",
    "conn.execute(\"\"\"create table steps (\n",
    "                program_id      int     primary key not NULL ,\n",
    "                program_name      text,\n",
    "                qualified_program_name  text)\n",
    "            \"\"\")\n",
    "\n",
    "#% FACT: workflow(program_id).\n",
    "\n",
    "conn.execute(\"\"\"create table workflow (\n",
    "                program_id      int\n",
    "                )\n",
    "            \"\"\")\n",
    "\n",
    "#% FACT: has_subprogram(program_id, subprogram_id).\n",
    "\n",
    "conn.execute(\"\"\"create table has_subprogram (\n",
    "                program_id  int,\n",
    "                sub_program_id      int\n",
    "                )\n",
    "            \"\"\")\n",
    "\n",
    "#% FACT: port(port_id, port_type, port_name, qualified_port_name, port_annotation_id, data_id).\n",
    "\n",
    "\n",
    "conn.execute(\"\"\"create table port (\n",
    "                port_id      int     primary key not NULL,\n",
    "                port_type  int,\n",
    "                port_name  text,\n",
    "                qualified_port_name text,\n",
    "                port_annotation_id int, \n",
    "                data_id int \n",
    "                )\n",
    "            \"\"\")\n",
    "\n",
    "\n",
    "\n",
    "# % FACT: port_alias(port_id, alias).\n",
    "\n",
    "conn.execute(\"\"\"create table port_alias (\n",
    "                port_id    int  ,\n",
    "                alias    text\n",
    "                )\n",
    "            \"\"\")\n",
    "\n",
    "#% FACT: has_in_port(block_id, port_id).\n",
    "\n",
    "conn.execute(\"\"\"create table has_in_port (\n",
    "                block_id int,\n",
    "                port_id    int\n",
    "                )\n",
    "            \"\"\")\n",
    "\n",
    "#% FACT: has_out_port(block_id, port_id).\n",
    "\n",
    "conn.execute(\"\"\"create table has_out_port (\n",
    "                block_id int,\n",
    "                port_id    int\n",
    "                )\n",
    "            \"\"\")\n",
    "\n",
    "#% FACT: data(data_id, data_name, qualified_data_name).\n",
    "\n",
    "conn.execute(\"\"\"create table data (\n",
    "                data_id int,\n",
    "                data_name    text,\n",
    "                qualified_data_name text\n",
    "                )\n",
    "            \"\"\")\n",
    "\n",
    "#% FACT: channel(channel_id, data_id).\n",
    "\n",
    "\n",
    "conn.execute(\"\"\"create table channel (\n",
    "                channel_id int,\n",
    "                data_id    int\n",
    "                )\n",
    "            \"\"\")\n",
    "\n",
    "#% FACT: port_connects_to_channel(port_id, channel_id).\n",
    "\n",
    "conn.execute(\"\"\"create table port_connects_to_channel (\n",
    "                port_id int,\n",
    "                channel_id    int\n",
    "                )\n",
    "            \"\"\")\n",
    "    \n",
    "# % FACT: inflow_connects_to_channel(port_id, channel_id).\n",
    "conn.execute(\"\"\"create table inflow_connects_to_channel (\n",
    "                port_id int,\n",
    "                channel_id    int\n",
    "                )\n",
    "            \"\"\")\n",
    "\n",
    "\n",
    "#% FACT: outflow_connects_to_channel(port_id, channel_id).\n",
    "conn.execute(\"\"\"create table outflow_connects_to_channel (\n",
    "                port_id int,\n",
    "                channel_id    int\n",
    "                )\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "read_yw_model(yw_model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql_steps_in_out_ports = '''\n",
    "select \n",
    "\twf.wf_id as workflow_id , s.program_id as program_id, s.program_name as program_name,\n",
    "\tp.port_name as port_name, p.qualified_port_name as qname, p.port_id as port_id, p.port_type as port_type , p.data_id as data_id   \n",
    "from \n",
    "\tsteps s, port p, has_in_port inp, \n",
    "\t(select \n",
    "\t\tsub_program_id  , program_id as wf_id \n",
    "\t from \n",
    "\t\thas_subprogram\n",
    "\t) wf\n",
    "where \n",
    "\ts.program_id = inp.block_id\n",
    "and\tp.port_id = inp.port_id \n",
    "and inp.block_id  = wf.sub_program_id\n",
    "union \n",
    "select \n",
    "\twf.wf_id as workflow_id , s.program_id as program_id, s.program_name as program_name,\n",
    "\tp.port_name as port_name,p.qualified_port_name as qname, p.port_id as port_id, p.port_type as port_type , p.data_id as data_id \n",
    "from \n",
    "\tsteps s, port p, has_out_port out,\n",
    "\t(select \n",
    "\t\tsub_program_id  , program_id as wf_id \n",
    "\t from \n",
    "\t\thas_subprogram\n",
    "\t) wf\n",
    "where \n",
    "\ts.program_id = out.block_id\n",
    "and\tp.port_id = out.port_id \n",
    "and out.block_id = wf.sub_program_id\n",
    "'''\n",
    "\n",
    "\n",
    "sql_wf_ports = '''\n",
    "select \n",
    "\ts.program_id, s.program_name, p.port_name, p.port_id, p.port_type, p.data_id  \n",
    "from \n",
    "\tsteps s, port p, has_in_port inp \n",
    "where \n",
    "\ts.program_id = inp.block_id\n",
    "and\tp.port_id = inp.port_id \n",
    "and inp.block_id in \n",
    "\t(select \n",
    "\t\tprogram_id  \n",
    "\t from \n",
    "\t\tworkflow\n",
    "\t)\n",
    "union \n",
    "select \n",
    "\ts.program_id, s.program_name, p.port_name,p.port_id, p.port_type , p.data_id\n",
    "from \n",
    "\tsteps s, port p, has_out_port out \n",
    "where \n",
    "\ts.program_id = out.block_id\n",
    "and\tp.port_id = out.port_id \n",
    "and out.block_id in \n",
    "\t(select \n",
    "\t\tprogram_id  \n",
    "\t from \n",
    "\t\tworkflow\n",
    "\t)\n",
    "'''\n",
    "\n",
    "sql_qual_portname = '''\n",
    "select \n",
    "\tdistinct p.program_id as workflow_id,  p.port_id,  p.program_name, p.port_name ,p.port_name as qualified_portname, p.port_type , p.data_id\n",
    "from\n",
    "\twf_ports p, inflow_connects_to_channel q\n",
    " where upper(p.port_type) in ('IN')\n",
    " and p.port_id = q.port_id\n",
    "union \n",
    "select\n",
    "\tp.workflow_id, p.port_id, p.program_name, p.port_name, p.program_name || '/' || p.port_name as qualified_portname, p.port_type , p.data_id\n",
    "from\n",
    "\tcwl_steps_info p\n",
    "where upper(p.port_type)= 'OUT'\n",
    "union\n",
    "select\n",
    "\tp.program_id as workflow_id, p.port_id, p.program_name, p.port_name, p.port_name as qualified_portname, p.port_type , p.data_id\n",
    "from\n",
    "\twf_ports p, port po\n",
    "where p.port_id = po.port_id \n",
    "and upper(po.port_name) like '_YW_IN%'\n",
    "'''\n",
    "\n",
    "sql_wf_qual_out_port = '''\n",
    "select \n",
    "\tp.program_name, q.port_name, p.program_name || '/' || p.port_name as qualified_portname, p.port_type , p.data_id\n",
    "from \n",
    "\tcwl_steps_info p , port q\n",
    "where q.port_id = p.port_id\n",
    "and p.port_id in \n",
    "\t(\n",
    "\tselect \n",
    "\t\tport_id\n",
    "\tfrom \n",
    "\t\tport_connects_to_channel\n",
    "\twhere \n",
    "\t\tchannel_id in \n",
    "\t\t(select \n",
    "\t\t\tmax(channel_id)\n",
    "\t\tfrom \n",
    "\t\t\toutflow_connects_to_channel\n",
    "\t\tgroup by port_id\n",
    "\t\t)\n",
    "\t)\n",
    "union \n",
    "select \n",
    "\tp.program_name, pa.alias as port_name, p.program_name || '/' || p.port_name as qualified_portname, p.port_type , p.data_id\n",
    "from \n",
    "\tcwl_steps_info p , port q, port_alias pa\n",
    "where q.port_id = p.port_id\n",
    "and p.port_id = pa.port_id\n",
    "and p.port_id in \n",
    "\t(\n",
    "\tselect \n",
    "\t\tport_id\n",
    "\tfrom \n",
    "\t\tport_connects_to_channel\n",
    "\twhere \n",
    "\t\tchannel_id in \n",
    "\t\t(select \n",
    "\t\t\tmax(channel_id)\n",
    "\t\tfrom \n",
    "\t\t\toutflow_connects_to_channel\n",
    "\t\tgroup by port_id\n",
    "\t\t)\n",
    "\t)\n",
    "union\n",
    "select \n",
    "\tp.qualified_port_name, p.port_name,  p.qualified_port_name, p.port_type , p.data_id\n",
    "from \n",
    "\tport p \n",
    "where p.port_name like '_YW_OUT%'\n",
    "'''\n",
    "\n",
    "sql_dangling_port_id = \"\"\"\n",
    "select \n",
    "\tport_id \n",
    "from\n",
    "\tport \n",
    "where data_id in \n",
    "(\n",
    "\tselect distinct data_id from port  \n",
    "\tEXCEPT\n",
    "\tselect distinct data_id  from channel\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "sql_port_alias = '''\n",
    "select \n",
    "    port_id, alias\n",
    "from \n",
    "    port_alias'''\n",
    "\n",
    "sql_multiwriter_port = '''\n",
    "select \n",
    "\tcwf.workflow_id as workflow_id , cwf.program_id as program_id, cwf.program_name as program_name,cwf.port_name as port_name, cwf.port_id as port_id, cwf.port_type as port_type , cwf.data_id as data_id \n",
    "from \n",
    "\tcwl_steps_info cwf\n",
    "where port_type = 'OUT'\n",
    "and cwf.data_id in \n",
    "\t(\n",
    "\tselect \n",
    "\t\tdata_id\n",
    "\tfrom \n",
    "\t\tcwl_steps_info\n",
    "\twhere port_type ='OUT'\n",
    "\tgroup by data_id\n",
    "\thaving count(1) > 1\n",
    "\t)\n",
    "'''\n",
    "#df_dangling_ports = pd.read_sql_query(sql_dangling_port_id, con=conn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x107a0d180>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.execute('create table if not exists cwl_steps_info as ' + sql_steps_in_out_ports)\n",
    "#conn.execute('create table wf_ports as ' + sql_wf_ports)\n",
    "#conn.execute('create table qual_portname as ' + sql_qual_portname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cwl_file_df = pd.DataFrame()\n",
    "wf_port_df = pd.DataFrame()\n",
    "qual_portname = pd.DataFrame()\n",
    "qual_wf_out_port = pd.DataFrame()\n",
    "df_dangling_ports = pd.DataFrame()\n",
    "df_port_alias = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cwl_file_df = pd.read_sql_query(sql_steps_in_out_ports, con=conn)\n",
    "wf_port_df = pd.read_sql_query(sql_wf_ports, con=conn)\n",
    "df_dangling_ports = pd.read_sql_query(sql_dangling_port_id, con=conn)\n",
    "df_port_alias = pd.read_sql_query(sql_port_alias, con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Add an output port in the ports tables\n",
    "def ins_out_port(program_name):\n",
    "    wf_id = cwl_file_df[cwl_file_df['program_name'] == program_name]['workflow_id'].values[0]\n",
    "    prog_id = cwl_file_df[cwl_file_df['program_name'] == program_name]['program_id'].values[0]\n",
    "    port_id = cwl_file_df['port_id'].max() + 1\n",
    "    data_id = cwl_file_df['data_id'].max() + 1\n",
    "    #print(port_id, data_id)\n",
    "    port_type = 'OUT'\n",
    "    port_name = '_YW_OUT_'+ program_name\n",
    "    qual_prog_name = program_name + '/' + port_name\n",
    "    sql = \"\"\"\n",
    "    insert into port values (?,?,?,?,?,?)\n",
    "    \"\"\"\n",
    "    data = [int(port_id), port_type, port_name,qual_prog_name,port_id,int(data_id)]\n",
    "    conn.execute(sql,data)\n",
    "    \n",
    "    sql = \"\"\"\n",
    "    insert into has_out_port values (?,?)\n",
    "    \"\"\"\n",
    "    data = [int(wf_id),int(port_id)]\n",
    "    conn.execute(sql,data)\n",
    "    data = [int(prog_id),int(port_id)]\n",
    "    conn.execute(sql,data)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Add an output port in the ports tables\n",
    "def ins_link_wf_port(port_id, wf_id,port_type,program_name):\n",
    "    #print(port_id, data_id)\n",
    "    new_port_id = get_max_port_id() + 1\n",
    "    data_id = cwl_file_df[cwl_file_df['port_id'] == port_id]['data_id']\n",
    "    #print(type(new_port_id))\n",
    "    \n",
    "    port_name = cwl_file_df[cwl_file_df['port_id'] == port_id]['port_name'].values[0]\n",
    "    \n",
    "    print(port_name)\n",
    "    if port_type == 'OUT':\n",
    "        wf_port_name = '_YW_OUT_'+ port_name\n",
    "        qual_prog_name = program_name + '/' + port_name\n",
    "        sql_link = \"\"\"\n",
    "                   insert into has_out_port values (?,?)\n",
    "                   \"\"\"\n",
    "        values = [int(wf_id),int(new_port_id)]\n",
    "    else: \n",
    "        wf_port_name = '_YW_IN_'+ port_name\n",
    "        qual_prog_name =  wf_port_name\n",
    "        sql_link = \"\"\"\n",
    "                   insert into has_in_port values (?,?)\n",
    "                   \"\"\"   \n",
    "        values = [int(wf_id),int(new_port_id)]\n",
    "        \n",
    "    print(qual_prog_name)\n",
    "    sql = \"\"\"\n",
    "    insert into port values (?,?,?,?,?,?)\n",
    "    \"\"\"\n",
    "    \n",
    "    data = [int(new_port_id), port_type, wf_port_name,qual_prog_name,port_id,int(data_id)]\n",
    "    conn.execute(sql,data)\n",
    "    #print(data)\n",
    "    #print(values)\n",
    "    conn.execute(sql_link,values)\n",
    "    conn.commit()\n",
    "    \n",
    "    #rebuild_dataframes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_max_port_id():\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('''SELECT max(port_id) from port ''')\n",
    "    max_port_id = cur.fetchone()\n",
    "    \n",
    "    return int(max_port_id[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for the dangling ports and create \n",
    "## the respective ports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the list of the dangling port id's and pass into the DF. \n",
    "for idx in cwl_file_df[cwl_file_df['port_id'].isin(df_dangling_ports['port_id'])].index:\n",
    "    wf_id = cwl_file_df.loc[idx]['workflow_id']\n",
    "    port_id = cwl_file_df.loc[idx]['port_id']\n",
    "    port_type = cwl_file_df.loc[idx]['port_type']\n",
    "    program_name = cwl_file_df.loc[idx]['program_name']\n",
    "    ins_link_wf_port(port_id, wf_id,port_type,program_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Check for the programs without output ports\n",
    "### use the ins_out_port to create the output port for wf and prog. \n",
    "\n",
    "program_name_uniq = cwl_file_df['program_name'].unique()\n",
    "program_with_out  = cwl_file_df[cwl_file_df['port_type'] == 'OUT'][\"program_name\"].unique()\n",
    "prog_wo_outport = list(set(program_name_uniq).difference(set(program_with_out)))\n",
    "\n",
    "for prog in prog_wo_outport:\n",
    "    #print(prog)\n",
    "    ins_out_port(prog)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reload the dataframes now \n",
    "\n",
    "conn.execute (''' drop table if exists cwl_steps_info ''')\n",
    "conn.execute (''' drop table if exists wf_ports ''')\n",
    "conn.execute (''' drop table if exists qual_portname ''')\n",
    "\n",
    "conn.execute('create table if not exists cwl_steps_info as ' + sql_steps_in_out_ports)\n",
    "conn.execute('create table if not exists wf_ports as ' + sql_wf_ports)\n",
    "conn.execute('create table if not exists qual_portname as ' + sql_qual_portname)\n",
    "conn.execute('create table if not exists qual_portname as ' + sql_qual_portname)\n",
    "\n",
    "cwl_file_df = pd.read_sql_query(sql_steps_in_out_ports, con=conn)\n",
    "wf_port_df = pd.read_sql_query(sql_wf_ports, con=conn)\n",
    "qual_portname = pd.read_sql_query(sql_qual_portname, con=conn)\n",
    "qual_wf_out_port = pd.read_sql_query(sql_wf_qual_out_port, con=conn)\n",
    "df_dangling_ports = pd.read_sql_query(sql_dangling_port_id, con=conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_filename(program_id, is_wf):\n",
    "    wfid_list = wf_port_df['program_id'].unique()\n",
    "    if is_wf:\n",
    "        program_name =wf_port_df[wf_port_df['program_id'] ==program_id]['program_name'].values[0]\n",
    "        return 'wf_' + program_name + '.cwl'\n",
    "    elif program_id in wfid_list:      \n",
    "        program_name = cwl_file_df[cwl_file_df['program_id'] ==program_id]['program_name'].values[0]\n",
    "        return 'wf_' + program_name + '.cwl'\n",
    "    else:\n",
    "        program_name = cwl_file_df[cwl_file_df['program_id'] ==program_id]['program_name'].values[0]\n",
    "        return program_name + '.cwl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_cwl_file(filename, header, input_params, output_params):\n",
    "    #print(filename)\n",
    "    with open(filename,'w+') as writer: \n",
    "        writer.write(header)\n",
    "        writer.write(input_params)\n",
    "        writer.write(output_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_wf_steps(workflow_id):\n",
    "    header_step = \"steps: \\n \"\n",
    "    buffer=''\n",
    "    prog_list = cwl_file_df[cwl_file_df['workflow_id'] == workflow_id]['program_id'].unique()\n",
    "    \n",
    "    for prog in prog_list: \n",
    "        outport_list= []\n",
    "        prog_name = cwl_file_df[cwl_file_df['program_id'] ==prog]['program_name'].values[0]\n",
    "        filename = get_filename(prog,False)\n",
    "        \n",
    "\n",
    "\n",
    "        buffer = buffer + prog_name + ': \\n ' + ' run: ' +filename + ' \\n ' + ' in: \\n'\n",
    "        \n",
    "        for pid in cwl_file_df[cwl_file_df[\"program_id\"]==prog].index:\n",
    "            \n",
    "            port_id = cwl_file_df.loc[pid]['port_id'] \n",
    "            port_name = cwl_file_df.loc[pid]['port_name'] \n",
    "            port_type = cwl_file_df.loc[pid]['port_type']       \n",
    "            data_id = cwl_file_df.loc[pid]['data_id']\n",
    "            \n",
    "            if port_type == 'IN':\n",
    "                \n",
    "                filtered_df =  qual_portname[qual_portname[\"workflow_id\"] == workflow_id]\n",
    "                qn_df = filtered_df[filtered_df[\"data_id\"] == data_id][\"qualified_portname\"]\n",
    "                \n",
    "                if len(qn_df) == 0 :\n",
    "                    alias = df_port_alias[df_port_alias[\"port_id\"]==port_id]['alias']\n",
    "                    if len(alias) != 0 :\n",
    "                        qname = alias.values[0]\n",
    "                    else:\n",
    "                        qname = port_name\n",
    "                else: \n",
    "                    if '_YW_IN_' in port_name:\n",
    "                        qname = cwl_file_df.loc[pid]['qname']\n",
    "                    else:\n",
    "                        qname = qn_df.values[0]\n",
    "                buffer = buffer + '   ' + port_name + ': ' + qname + '\\n'\n",
    "            else: \n",
    "                outport_list.append(port_name)\n",
    "            #break\n",
    "        buffer = buffer + \"  out: [\" + ','.join(outport_list) + '] \\n '    \n",
    "    \n",
    "    return header_step + buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps: \n",
      " print_message: \n",
      "  run: print_message.cwl \n",
      "  in: \n",
      "   verbose: verbose\n",
      "  out: [_YW_OUT_print_message] \n",
      " get_predictor_matrix: \n",
      "  run: get_predictor_matrix.cwl \n",
      "  in: \n",
      "   calibration_years: calibration_years\n",
      "   itrdb: itrdb\n",
      "   min_width: min_width\n",
      "  out: [max_preds,predictor_matrix] \n",
      " get_reconstruction_matrix: \n",
      "  run: get_reconstruction_matrix.cwl \n",
      "  in: \n",
      "   itrdb: itrdb\n",
      "   min_width: min_width\n",
      "   prediction_years: prediction_years\n",
      "  out: [reconstruction_matrix] \n",
      " get_predlist: \n",
      "  run: get_predlist.cwl \n",
      "  in: \n",
      "   reconstruction_matrix: get_reconstruction_matrix/reconstruction_matrix\n",
      "  out: [predlist] \n",
      " get_carscores: \n",
      "  run: get_carscores.cwl \n",
      "  in: \n",
      "   predictor_matrix: get_predictor_matrix/predictor_matrix\n",
      "   prism_data_for_coordinates: prism_data_for_coordinates\n",
      "  out: [carscores] \n",
      " calculate_Models: \n",
      "  run: wf_calculate_Models.cwl \n",
      "  in: \n",
      "   carscores: get_carscores/carscores\n",
      "   max_preds: get_predictor_matrix/max_preds\n",
      "   predlist: get_predlist/predlist\n",
      "  out: [linear_models] \n",
      " optimizeModels: \n",
      "  run: optimizeModels.cwl \n",
      "  in: \n",
      "   linear_models: calculate_Models/linear_models\n",
      "  out: [paleocar_models] \n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(get_wf_steps(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## creating the cwl files and the wf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_sql/paleocar_models\n"
     ]
    }
   ],
   "source": [
    "\n",
    "wf_id = cwl_file_df['workflow_id'].unique()\n",
    "prog_list = cwl_file_df['program_id'].unique()\n",
    "dirname = 'example_sql/' + wf_port_df[wf_port_df[\"program_id\"] ==1]['program_name'].values[0]\n",
    "\n",
    "print(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print_message\n",
      "_YW_OUT_print_message OUT\n",
      "print_message\n",
      "verbose IN\n",
      "get_predictor_matrix\n",
      "calibration_years IN\n",
      "get_predictor_matrix\n",
      "itrdb IN\n",
      "get_predictor_matrix\n",
      "max_preds OUT\n",
      "get_predictor_matrix\n",
      "min_width IN\n",
      "get_predictor_matrix\n",
      "predictor_matrix OUT\n",
      "get_reconstruction_matrix\n",
      "itrdb IN\n",
      "get_reconstruction_matrix\n",
      "min_width IN\n",
      "get_reconstruction_matrix\n",
      "prediction_years IN\n",
      "get_reconstruction_matrix\n",
      "reconstruction_matrix OUT\n",
      "get_predlist\n",
      "predlist OUT\n",
      "get_predlist\n",
      "reconstruction_matrix IN\n",
      "get_carscores\n",
      "carscores OUT\n",
      "get_carscores\n",
      "predictor_matrix IN\n",
      "get_carscores\n",
      "prism_data_for_coordinates IN\n",
      "calculate_Models\n",
      "carscores IN\n",
      "calculate_Models\n",
      "linear_models OUT\n",
      "calculate_Models\n",
      "max_preds IN\n",
      "calculate_Models\n",
      "predlist IN\n",
      "optimizeModels\n",
      "linear_models IN\n",
      "optimizeModels\n",
      "paleocar_models OUT\n",
      "defineLinearModels\n",
      "carscores IN\n",
      "defineLinearModels\n",
      "matches OUT\n",
      "defineLinearModels\n",
      "max_preds IN\n",
      "defineLinearModels\n",
      "models OUT\n",
      "defineLinearModels\n",
      "predlist IN\n",
      "calculateLinearModels\n",
      "coefficients OUT\n",
      "calculateLinearModels\n",
      "matches IN\n",
      "calculateLinearModels\n",
      "model_errors OUT\n",
      "calculateLinearModels\n",
      "models IN\n",
      "simplifyLinearModels\n",
      "coefficients IN\n",
      "simplifyLinearModels\n",
      "final_models OUT\n",
      "simplifyLinearModels\n",
      "model_errors IN\n"
     ]
    }
   ],
   "source": [
    "for prog_id in prog_list: \n",
    "\n",
    "    cwl_file_header = '''\n",
    "#!/usr/bin/env cwl-runner\n",
    "cwlVersion: v1.0\n",
    "class: CommandLineTool\n",
    "'''\n",
    "    input_buffer = 'inputs: \\n'\n",
    "    output_buffer = 'outputs: \\n'\n",
    "    \n",
    "    pname = cwl_file_df[cwl_file_df[\"program_id\"] == [prog_id]]['program_name'].values[0]\n",
    "    #print(prog_id)\n",
    "    filename = dirname + '/' + get_filename(prog_id, False)\n",
    "\n",
    "    #print(filename)\n",
    "    for p_idx in cwl_file_df[cwl_file_df[\"program_id\"] == [prog_id]].index:\n",
    "        #pname = cwl_file_df.loc[p_idx]['program_name']\n",
    "        pid = cwl_file_df.loc[p_idx]['program_id']\n",
    "        print(pname)\n",
    "        port_name = cwl_file_df.loc[p_idx]['port_name'] \n",
    "        port_type = cwl_file_df.loc[p_idx]['port_type'] \n",
    "        print(port_name, port_type)\n",
    "\n",
    "        if port_type == 'IN':\n",
    "            input_buffer = input_buffer + ' '+ port_name + ': \\n'+ '  type: string \\n \\n'\n",
    "            #print(input_buffer)\n",
    "        else: \n",
    "            output_buffer = output_buffer + ' '+ port_name + ': \\n'+ '  type: string \\n \\n'\n",
    "            #print(output_buffer)\n",
    "    \n",
    "    output_buffer = output_buffer + \"baseCommand: \"\n",
    "    write_cwl_file(filename, cwl_file_header, input_buffer, output_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_models\n",
      "_YW_OUT_print_message\n",
      "paleocar_models\n"
     ]
    }
   ],
   "source": [
    "cwl_wf_header = '''\n",
    "#!/usr/bin/env cwl-runner\n",
    "cwlVersion: v1.0\n",
    "class: Workflow\n",
    "requirements:\n",
    "    - class: SubworkflowFeatureRequirement\n",
    "\n",
    "'''\n",
    "workflow_list = wf_port_df['program_id'].unique()\n",
    "\n",
    "for id in sorted(workflow_list, reverse=True):\n",
    "    input_buffer = 'inputs: \\n'\n",
    "    output_buffer = 'outputs: \\n'\n",
    "    #print(id)\n",
    "    wf_name = wf_port_df[wf_port_df['program_id']== id][\"program_name\"].values[0]\n",
    "    filename= dirname +'/' + get_filename(id, True)\n",
    "    #print(filename)\n",
    "    for p_id in wf_port_df[wf_port_df['program_id']== id].index:\n",
    "        prog_id = wf_port_df.loc[p_id]['program_id']\n",
    "        #print(int(prog_id))\n",
    "\n",
    "\n",
    "        pname = wf_port_df.loc[p_id]['program_name']\n",
    "        port_name = wf_port_df.loc[p_id]['port_name'] \n",
    "        port_type = wf_port_df.loc[p_id]['port_type'] \n",
    "        data_id = wf_port_df.loc[p_id]['data_id'] \n",
    "\n",
    "\n",
    "        if port_type == 'IN':\n",
    "            input_buffer = input_buffer + ' '+ port_name + ': \\n'+ '  type: string \\n \\n'\n",
    "            #print(input_buffer)\n",
    "        else: \n",
    "            print(port_name)\n",
    "            qn_df = qual_wf_out_port[qual_wf_out_port['port_name'] == port_name]\n",
    "            #print(qn_df)\n",
    "            if qn_df.shape[0] > 1:\n",
    "                print(qn_df['qualified_portname'].values[0])\n",
    "            else:\n",
    "                qname = qn_df['qualified_portname'].values[0]\n",
    "            output_buffer = output_buffer + '  ' +  port_name  + ': \\n' + '   type: string \\n   outputSource: '+ qname +'\\n'\n",
    "            #print(output_buffer)\n",
    "    \n",
    "    wf_step_contents = get_wf_steps(id)\n",
    "    write_cwl_file(filename,cwl_wf_header + input_buffer, output_buffer, wf_step_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>program_name</th>\n",
       "      <th>port_name</th>\n",
       "      <th>qualified_portname</th>\n",
       "      <th>port_type</th>\n",
       "      <th>data_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>optimizeModels</td>\n",
       "      <td>paleocar_models</td>\n",
       "      <td>optimizeModels/paleocar_models</td>\n",
       "      <td>OUT</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>print_message/_YW_OUT_print_message</td>\n",
       "      <td>_YW_OUT_print_message</td>\n",
       "      <td>print_message/_YW_OUT_print_message</td>\n",
       "      <td>OUT</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>simplifyLinearModels</td>\n",
       "      <td>final_models</td>\n",
       "      <td>simplifyLinearModels/final_models</td>\n",
       "      <td>OUT</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>simplifyLinearModels</td>\n",
       "      <td>linear_models</td>\n",
       "      <td>simplifyLinearModels/final_models</td>\n",
       "      <td>OUT</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          program_name              port_name  \\\n",
       "0                       optimizeModels        paleocar_models   \n",
       "1  print_message/_YW_OUT_print_message  _YW_OUT_print_message   \n",
       "2                 simplifyLinearModels           final_models   \n",
       "3                 simplifyLinearModels          linear_models   \n",
       "\n",
       "                    qualified_portname port_type  data_id  \n",
       "0       optimizeModels/paleocar_models       OUT       28  \n",
       "1  print_message/_YW_OUT_print_message       OUT       29  \n",
       "2    simplifyLinearModels/final_models       OUT       27  \n",
       "3    simplifyLinearModels/final_models       OUT       27  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qual_wf_out_port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_max_prog_id():\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('''SELECT max(program_id) as max_program_id from steps ''')\n",
    "    max_program_id = cur.fetchone()\n",
    "    \n",
    "    return int(max_program_id[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_max_outport_channel_id(port_id):\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(''' select \n",
    "\t\t\tmax(channel_id)\n",
    "\t\tfrom \n",
    "\t\t\toutflow_connects_to_channel\n",
    "        where port_id = :port_id\n",
    "\t\tgroup by port_id\n",
    "        ''', {'port_id':port_id})\n",
    "    max_channel_id = cur.fetchone()\n",
    "    \n",
    "    return int(max_channel_id[0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_max_outport_channel_id(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add an output port in the ports tables\n",
    "def ins_yw_program(wf_id, data_id,multiport_id, multi_port_name):\n",
    "    prog_id = get_max_prog_id() + 1\n",
    "    yw_prog_name = '_YW_PROG_' + str(prog_id )\n",
    "    \n",
    "    sql_prog = \"\"\"\n",
    "               insert into steps values(?,?,?) \n",
    "               \"\"\"\n",
    "\n",
    "    #print([prog_id, yw_prog_name, yw_prog_name])\n",
    "    \n",
    "    sql_inprog = \"\"\"\n",
    "                 insert into has_subprogram values(?,?)\n",
    "                 \"\"\"   \n",
    "    values = [int(wf_id), prog_id]\n",
    "    #print(values)\n",
    "    conn.execute(sql_prog,[prog_id, yw_prog_name, yw_prog_name])\n",
    "    conn.commit()\n",
    "    conn.execute(sql_inprog,values)\n",
    "    conn.commit()\n",
    "    \n",
    "    port_type = 'OUT'\n",
    "    new_port_id = get_max_port_id() +1 \n",
    "    wf_port_name = '_YW_OUT' + yw_prog_name\n",
    "    \n",
    "    sql_port = \"\"\"\n",
    "               insert into port values (?,?,?,?,?,?)\n",
    "               \"\"\" \n",
    "    data = [int(new_port_id), port_type, wf_port_name,yw_prog_name + '/'+ wf_port_name,new_port_id,int(data_id)]\n",
    "    \n",
    "    conn.execute(sql_port,data)\n",
    "    conn.commit()\n",
    "\n",
    "    sql_link = \"\"\"\n",
    "               insert into has_out_port values (?,?)\n",
    "               \"\"\"   \n",
    "    values = [int(prog_id),int(new_port_id)]\n",
    "    #print(values)\n",
    "    \n",
    "    conn.execute(sql_link,values)\n",
    "    conn.commit()       \n",
    "    \n",
    "    channel_id = get_max_outport_channel_id(int(multiport_id))\n",
    "    sql_upd = \"\"\"\n",
    "              update port_connects_to_channel set port_id = :port_id where channel_id =:channel_id\n",
    "              \"\"\"\n",
    "    conn.execute(sql_upd,  {\"channel_id\": channel_id, \"port_id\":new_port_id})\n",
    "    conn.commit()\n",
    "    \n",
    "    sql_link = \"\"\"\n",
    "               insert into port_alias values (?,?)\n",
    "               \"\"\"   \n",
    "    values = [int(new_port_id),multi_port_name]\n",
    "    conn.execute(sql_link,values)\n",
    "    conn.commit()       \n",
    "    \n",
    "    return prog_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Add an output port in the ports tables\n",
    "def ins_yw_prog_ports(new_program_id, port_id,port_name, qual_prog_name, data_id):\n",
    "    \n",
    "    port_type = 'IN'\n",
    "    new_port_id = get_max_port_id() +1 \n",
    "    wf_port_name = '_YW_IN_' + port_name + '_' + str(new_port_id)\n",
    "    \n",
    "    sql_port = \"\"\"\n",
    "               insert into port values (?,?,?,?,?,?)\n",
    "               \"\"\" \n",
    "    data = [int(new_port_id), port_type, wf_port_name,qual_prog_name,port_id,int(data_id)]\n",
    "    \n",
    "    conn.execute(sql_port,data)\n",
    "    conn.commit()\n",
    "\n",
    "    sql_link = \"\"\"\n",
    "               insert into has_in_port values (?,?)\n",
    "               \"\"\"   \n",
    "    values = [int(new_program_id),int(new_port_id)]\n",
    "    print(values)\n",
    "    \n",
    "    conn.execute(sql_link,values)\n",
    "    conn.commit()\n",
    "    \n",
    "    #rebuild_dataframes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_data = \"\"\"\n",
    "select \n",
    "    * \n",
    "from \n",
    "    data\n",
    "\"\"\"\n",
    "df_multiwriter_port= pd.read_sql_query(sql_multiwriter_port, con=conn)\n",
    "df_data= pd.read_sql_query(sql_data, con=conn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_id</th>\n",
       "      <th>data_name</th>\n",
       "      <th>qualified_data_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>prediction_years</td>\n",
       "      <td>[prediction_years]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>prism_data_for_coordinates</td>\n",
       "      <td>[prism_data_for_coordinates]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>itrdb</td>\n",
       "      <td>[itrdb]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>calibration_years</td>\n",
       "      <td>[calibration_years]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>min_width</td>\n",
       "      <td>[min_width]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>verbose</td>\n",
       "      <td>[verbose]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>paleocar_models</td>\n",
       "      <td>[paleocar_models]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>verbose</td>\n",
       "      <td>paleocar_models[verbose]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>itrdb</td>\n",
       "      <td>paleocar_models[itrdb]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>calibration_years</td>\n",
       "      <td>paleocar_models[calibration_years]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>min_width</td>\n",
       "      <td>paleocar_models[min_width]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>predictor_matrix</td>\n",
       "      <td>paleocar_models[predictor_matrix]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>max_preds</td>\n",
       "      <td>paleocar_models[max_preds]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>prediction_years</td>\n",
       "      <td>paleocar_models[prediction_years]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>reconstruction_matrix</td>\n",
       "      <td>paleocar_models[reconstruction_matrix]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>predlist</td>\n",
       "      <td>paleocar_models[predlist]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>prism_data_for_coordinates</td>\n",
       "      <td>paleocar_models[prism_data_for_coordinates]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>carscores</td>\n",
       "      <td>paleocar_models[carscores]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>linear_models</td>\n",
       "      <td>paleocar_models[linear_models]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>28</td>\n",
       "      <td>paleocar_models</td>\n",
       "      <td>paleocar_models[paleocar_models]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>predlist</td>\n",
       "      <td>paleocar_models.calculate_Models[predlist]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>carscores</td>\n",
       "      <td>paleocar_models.calculate_Models[carscores]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>max_preds</td>\n",
       "      <td>paleocar_models.calculate_Models[max_preds]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>models</td>\n",
       "      <td>paleocar_models.calculate_Models[models]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>matches</td>\n",
       "      <td>paleocar_models.calculate_Models[matches]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>coefficients</td>\n",
       "      <td>paleocar_models.calculate_Models[coefficients]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>model_errors</td>\n",
       "      <td>paleocar_models.calculate_Models[model_errors]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>linear_models</td>\n",
       "      <td>paleocar_models.calculate_Models[linear_models]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    data_id                   data_name  \\\n",
       "0         1            prediction_years   \n",
       "1         2  prism_data_for_coordinates   \n",
       "2         3                       itrdb   \n",
       "3         4           calibration_years   \n",
       "4         5                   min_width   \n",
       "5         6                     verbose   \n",
       "6         7             paleocar_models   \n",
       "7         8                     verbose   \n",
       "8         9                       itrdb   \n",
       "9        10           calibration_years   \n",
       "10       11                   min_width   \n",
       "11       12            predictor_matrix   \n",
       "12       13                   max_preds   \n",
       "13       14            prediction_years   \n",
       "14       15       reconstruction_matrix   \n",
       "15       16                    predlist   \n",
       "16       17  prism_data_for_coordinates   \n",
       "17       18                   carscores   \n",
       "18       19               linear_models   \n",
       "19       28             paleocar_models   \n",
       "20       20                    predlist   \n",
       "21       21                   carscores   \n",
       "22       22                   max_preds   \n",
       "23       23                      models   \n",
       "24       24                     matches   \n",
       "25       25                coefficients   \n",
       "26       26                model_errors   \n",
       "27       27               linear_models   \n",
       "\n",
       "                                qualified_data_name  \n",
       "0                                [prediction_years]  \n",
       "1                      [prism_data_for_coordinates]  \n",
       "2                                           [itrdb]  \n",
       "3                               [calibration_years]  \n",
       "4                                       [min_width]  \n",
       "5                                         [verbose]  \n",
       "6                                 [paleocar_models]  \n",
       "7                          paleocar_models[verbose]  \n",
       "8                            paleocar_models[itrdb]  \n",
       "9                paleocar_models[calibration_years]  \n",
       "10                       paleocar_models[min_width]  \n",
       "11                paleocar_models[predictor_matrix]  \n",
       "12                       paleocar_models[max_preds]  \n",
       "13                paleocar_models[prediction_years]  \n",
       "14           paleocar_models[reconstruction_matrix]  \n",
       "15                        paleocar_models[predlist]  \n",
       "16      paleocar_models[prism_data_for_coordinates]  \n",
       "17                       paleocar_models[carscores]  \n",
       "18                   paleocar_models[linear_models]  \n",
       "19                 paleocar_models[paleocar_models]  \n",
       "20       paleocar_models.calculate_Models[predlist]  \n",
       "21      paleocar_models.calculate_Models[carscores]  \n",
       "22      paleocar_models.calculate_Models[max_preds]  \n",
       "23         paleocar_models.calculate_Models[models]  \n",
       "24        paleocar_models.calculate_Models[matches]  \n",
       "25   paleocar_models.calculate_Models[coefficients]  \n",
       "26   paleocar_models.calculate_Models[model_errors]  \n",
       "27  paleocar_models.calculate_Models[linear_models]  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_multiwriter_port.shape[0] > 1: \n",
    "    wf_id = df_multiwriter_port['workflow_id'].values[0]\n",
    "    data_id = df_multiwriter_port['data_id'].values[0]\n",
    "    \n",
    "    print(data_id)\n",
    "    multiport_name = df_data[df_data['data_id' ]== data_id]['data_name'].unique()[0]\n",
    "    print(data_id,multiport_name)\n",
    "    multiport_id = wf_port_df[wf_port_df['port_name'] ==multiport_name][\"port_id\"].values[0]\n",
    "    wf_data_id = wf_port_df[wf_port_df['port_name'] == multiport_name]['data_id'].values[0]\n",
    "    print(multiport_name,multiport_id)\n",
    "    new_prog_id = ins_yw_program(wf_id,wf_data_id,multiport_id,multiport_name)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_prog_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-a658e53277b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_prog_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_multiwriter_port\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mport_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_multiwriter_port\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'port_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mport_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_multiwriter_port\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'port_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mport_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_multiwriter_port\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'port_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_prog_id' is not defined"
     ]
    }
   ],
   "source": [
    "print(new_prog_id)\n",
    "for idx in df_multiwriter_port.index:\n",
    "    port_id = df_multiwriter_port.loc[idx]['port_id']\n",
    "    port_name = df_multiwriter_port.loc[idx]['port_name']    \n",
    "    port_type = df_multiwriter_port.loc[idx]['port_type']\n",
    "    program_name = df_multiwriter_port.loc[idx]['program_name']\n",
    "    data_id = df_multiwriter_port.loc[idx]['data_id']\n",
    "\n",
    "    ins_yw_prog_ports(new_prog_id,port_id,port_name, program_name+'/'+port_name, data_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wf_id = df_multiwriter_port['workflow_id'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cwl_file_df = pd.read_sql_query(sql_steps_in_out_ports, con=conn)\n",
    "wf_port_df = pd.read_sql_query(sql_wf_ports, con=conn)\n",
    "qual_portname = pd.read_sql_query(sql_qual_portname, con=conn)\n",
    "qual_wf_out_port = pd.read_sql_query(sql_wf_qual_out_port, con=conn)\n",
    "df_dangling_ports = pd.read_sql_query(sql_dangling_port_id, con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual_wf_out_port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Reload the dataframes now \n",
    "\n",
    "conn.execute (''' drop table if exists cwl_steps_info ''')\n",
    "conn.execute (''' drop table if exists wf_ports ''')\n",
    "conn.execute (''' drop table if exists qual_portname ''')\n",
    "\n",
    "conn.execute('create table if not exists cwl_steps_info as ' + sql_steps_in_out_ports)\n",
    "conn.execute('create table if not exists wf_ports as ' + sql_wf_ports)\n",
    "conn.execute('create table if not exists qual_portname as ' + sql_qual_portname)\n",
    "conn.execute('create table if not exists qual_portname as ' + sql_qual_portname)\n",
    "\n",
    "cwl_file_df = pd.read_sql_query(sql_steps_in_out_ports, con=conn)\n",
    "wf_port_df = pd.read_sql_query(sql_wf_ports, con=conn)\n",
    "qual_portname = pd.read_sql_query(sql_qual_portname, con=conn)\n",
    "qual_wf_out_port = pd.read_sql_query(sql_wf_qual_out_port, con=conn)\n",
    "df_dangling_ports = pd.read_sql_query(sql_dangling_port_id, con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwl_file_df['program_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
