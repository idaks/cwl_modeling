{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import sqlite3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yw_model_file = \"example_sql/C3_C4_map_present_NA/C3_C4_map_present_NA.P\"\n",
    "\n",
    "db_model = yw_model_file[:-2] + '.db'\n",
    "#print(db_model)\n",
    "conn = sqlite3.connect(db_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for parsing the yw models file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### function extracting the programs.\n",
    "\n",
    "def extract_steps(line):\n",
    "    \n",
    "    #% FACT: program(program_id, program_name, qualified_program_name, begin_annotation_id, end_annotation_id).\n",
    "    #print(\"Extracting steps.\")\n",
    "    ## Extract data between \"(\" and \")\".\n",
    "    data = line[line.index(\"(\")+1:line.index(\")\")]\n",
    "    \n",
    "    data = data.split(',')\n",
    "    #print(data)\n",
    "    \n",
    "    \n",
    "    ins_query = [data[0].strip().strip(\"'\"),data[1].strip().strip(\"'\"),data[2].strip().strip(\"'\")]\n",
    "    conn.execute(\"\"\"insert into steps values(?,?,?)\"\"\", ins_query)\n",
    "    conn.commit()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### function extracting the workflow.\n",
    "\n",
    "def extract_workflows(line):\n",
    "    \n",
    "    #print(line)\n",
    "    data = line[line.index(\"(\")+1:line.index(\")\")]\n",
    "    number = ''.join(data)\n",
    "    \n",
    "    conn.execute(\"\"\"insert into workflow values(?)\"\"\",[number])\n",
    "    conn.commit()\n",
    "      \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### function extracting the ports\n",
    "\n",
    "def extract_ports(line):\n",
    "    #print(\"Extracting ports.\")\n",
    "    ## Extract data between \"(\" and \")\".\n",
    "    data = line[line.index(\"(\")+1:line.index(\")\")]\n",
    "    \n",
    "    #% FACT: port(port_id, port_type, port_name, qualified_port_name, port_annotation_id, data_id).\n",
    "    \n",
    "    data = data.split(',')\n",
    "    \n",
    "    if data[1].strip().strip(\"'\").upper().strip('\"') == 'PARAM':\n",
    "        port_type = 'IN'\n",
    "    else:\n",
    "        port_type = data[1].strip().strip(\"'\").upper().strip('\"')\n",
    "    \n",
    "    ins_query = [data[0].strip().strip(\"'\"),port_type,data[2].strip().strip(\"'\"),data[3].strip().strip(\"'\")\n",
    "                 ,data[4].strip().strip(\"'\"),data[5].strip().strip(\"'\")]\n",
    "    conn.execute(\"\"\"insert into port values(?,?,?,?,?,?)\"\"\", ins_query)\n",
    "    conn.commit()\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### function extracting the input ports\n",
    "\n",
    "def input_ports(line):\n",
    "    #print(\"Extracting Input ports.\")\n",
    "    \n",
    "    ## Extract data between \"(\" and \")\".\n",
    "    ## % FACT: has_in_port(step_id, port_id).\n",
    "\n",
    "    data = line[line.index(\"(\")+1:line.index(\")\")]\n",
    "    \n",
    "    data = data.split(',')\n",
    "    ins_query = [data[0].strip().strip(\"'\").strip('\"'),data[1].strip().strip(\"'\").strip('\"')]\n",
    "    conn.execute(\"\"\"insert into has_in_port values(?,?)\"\"\", ins_query)\n",
    "    conn.commit()\n",
    "    \n",
    "    #in_ports[data[0]].append((data[0].strip(), data[1].strip()))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### function extracting the output ports \n",
    "\n",
    "def output_ports(line): \n",
    "    #print(\"Extracting output ports.\")\n",
    "    ## Extract data between \"(\" and \")\".\n",
    "    data = line[line.index(\"(\")+1:line.index(\")\")]\n",
    "    data = data.split(',')\n",
    "    ins_query = [data[0].strip().strip(\"'\").strip('\"'),data[1].strip().strip(\"'\").strip('\"')]\n",
    "    conn.execute(\"\"\"insert into has_out_port values(?,?)\"\"\", ins_query)\n",
    "    conn.commit()\n",
    "    #out_ports[data[0]].append((data[0].strip(), data[1].strip()))\n",
    "    #print(data)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### function extracting the subprograms \n",
    "\n",
    "def has_subprogram(line): \n",
    "    #print(\"Extracting output ports.\")\n",
    "    ## Extract data between \"(\" and \")\".\n",
    "    data = line[line.index(\"(\")+1:line.index(\")\")]\n",
    "    data = data.split(',')\n",
    "    \n",
    "    ins_query = [data[0].strip().strip(\"'\").strip('\"'),data[1].strip().strip(\"'\").strip('\"')]\n",
    "    conn.execute(\"\"\"insert into has_subprogram values(?,?)\"\"\", ins_query)\n",
    "    conn.commit()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### function extracting the output ports \n",
    "\n",
    "def get_port_connects_to_channel(line): \n",
    "     \n",
    "    data = line[line.index(\"(\")+1 : line.index(\")\")]\n",
    "    data = data.split(',')\n",
    "\n",
    "    ins_query = [data[0].strip().strip(\"'\"),data[1].strip().strip(\"'\")]\n",
    "    conn.execute(\"\"\"insert into port_connects_to_channel values(?,?)\"\"\", ins_query)\n",
    "    conn.commit()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_inflow_connections(line): \n",
    "     \n",
    "    #print(line)\n",
    "    data = line[line.index(\"(\")+1:line.index(\")\")]\n",
    "    data = data.split(',')\n",
    "    #inflow_conn[data[0]]= data[1].strip()\n",
    "    \n",
    "    ins_query = [data[0].strip().strip(\"'\").strip('\"'),data[1].strip().strip(\"'\").strip('\"')]\n",
    "    conn.execute(\"\"\"insert into inflow_connects_to_channel values(?,?)\"\"\", ins_query)\n",
    "    conn.commit()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_outflow_connections(line): \n",
    "    #print(\"Extracting output ports.\")\n",
    "    ## Extract data between \"(\" and \")\".\n",
    "    data = line[line.index(\"(\")+1:line.index(\")\")]\n",
    "    data = data.split(',')\n",
    "    #outflow_conn[data[0]]= data[1].strip()\n",
    "\n",
    "    ins_query = [data[0].strip().strip(\"'\").strip('\"'),data[1].strip().strip(\"'\").strip('\"')]\n",
    "    conn.execute(\"\"\"insert into outflow_connects_to_channel values(?,?)\"\"\", ins_query)\n",
    "    conn.commit()\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### function extracting the output ports \n",
    "\n",
    "def get_port_data(line): \n",
    "    #print(\"Extracting output ports.\")\n",
    "    ## Extract data between \"(\" and \")\".\n",
    "    data = line[line.index(\"(\")+1:line.index(\")\")]\n",
    "    data = data.split(',')\n",
    "    \n",
    "    ins_query = [data[0].strip().strip(\"'\"),data[1].strip().strip(\"'\"),data[2].strip().strip(\"'\")]\n",
    "    conn.execute(\"\"\"insert into data values(?,?,?)\"\"\", ins_query)\n",
    "    conn.commit()\n",
    "    #print(data)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### function extracting the output ports \n",
    "\n",
    "def get_channel(line): \n",
    "    #print(\"Extracting output ports.\")\n",
    "    ## Extract data between \"(\" and \")\".\n",
    "    data = line[line.index(\"(\")+1:line.index(\")\")]\n",
    "    data = data.split(',')\n",
    "    \n",
    "    ins_query = [data[0].strip().strip(\"'\").strip('\"'),data[1].strip().strip(\"'\").strip('\"')]\n",
    "    conn.execute(\"\"\"insert into channel values(?,?)\"\"\", ins_query)\n",
    "    conn.commit()\n",
    "    #channel[data[0]]= data[1].strip()\n",
    "    #print(data)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### function extracting the port alias\n",
    "\n",
    "def port_alias(line):\n",
    "    data = line[line.index(\"(\")+1:line.index(\")\")]\n",
    "    data = data.split(',')\n",
    "    \n",
    "    port_id = data[0].strip()\n",
    "    alias = data[1].strip().strip(\"'\")\n",
    "    \n",
    "    #print(port_name, port_id,qualified_name)\n",
    "    \n",
    "    ins_query = [data[0].strip().strip(\"'\").strip('\"'),data[1].strip().strip(\"'\").strip('\"')]\n",
    "    conn.execute(\"\"\"insert into port_alias values(?,?)\"\"\", ins_query)\n",
    "    conn.commit()\n",
    "    \n",
    "    '''\n",
    "    ### regex for splitting the string and getting qualified program name\n",
    "    regex = re.compile(r'>|<')\n",
    "    qname = regex.split(qualified_name)\n",
    "    \n",
    "    pname = qname[0].split('.')[-1] \n",
    "    \n",
    "    if pname.find('-') > -1:\n",
    "        port_alt_name[alias] = pname[:-1]+ '/' +port_name\n",
    "    else:\n",
    "        port_alt_name[alias] = pname + '/' +port_name\n",
    "       \n",
    "    '''\n",
    "    return \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_yw_model(filename):\n",
    "    regex = re.compile(r'^%')\n",
    "    chk_channel = re.compile(r'^ch')\n",
    "    with open(filename, \"r\") as yw_struct:\n",
    "        line = yw_struct.readline()\n",
    "        while line:\n",
    "            #print(line)\n",
    "            comments = regex.match(line)\n",
    "            if comments: \n",
    "                #print(line)\n",
    "                line = yw_struct.readline()\n",
    "            else:  \n",
    "                if(\"program(\" in line and \"has_subprogram\" not in line):\n",
    "                    extract_steps(line)\n",
    "                elif(\"workflow(\" in line):\n",
    "                    extract_workflows(line)            \n",
    "                elif(\"has_subprogram(\" in line):\n",
    "                    has_subprogram(line)            \n",
    "                elif(\"port(\" in line  and \"has_in_port(\" not in line and \"has_out_port\" not in line):\n",
    "                #    print(line)\n",
    "                    extract_ports(line)\n",
    "                elif(\"has_in_port(\" in line):\n",
    "                    input_ports(line)\n",
    "                elif(\"has_out_port(\" in line ):\n",
    "                    output_ports(line)\n",
    "                elif (\"port_alias(\" in line ): \n",
    "                    port_alias(line)\n",
    "                elif(\"data(\" in line):\n",
    "                    get_port_data(line)\n",
    "                elif(\"port_connects_to_channel(\" in line):\n",
    "                    #print(line)\n",
    "                    get_port_connects_to_channel(line)\n",
    "                elif(\"inflow_connects_to_channel(\"in line):\n",
    "                    #print(line)\n",
    "                    get_inflow_connections(line)                    \n",
    "                elif(\"outflow_connects_to_channel(\"in line):\n",
    "                    get_outflow_connections(line)\n",
    "                elif( chk_channel.match(line) ):\n",
    "                    get_channel(line)\n",
    "\n",
    "                line = yw_struct.readline()\n",
    "        \n",
    "        #get_in_out_ports()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()\n",
    "conn.execute (''' drop table if exists channel ''')                    \n",
    "conn.execute (''' drop table if exists data  ''')                 \n",
    "conn.execute (''' drop table if exists has_in_port ''')                  \n",
    "conn.execute (''' drop table if exists has_out_port ''')                \n",
    "conn.execute (''' drop table if exists has_subprogram ''')              \n",
    "conn.execute (''' drop table if exists inflow_connects_to_channel ''')  \n",
    "conn.execute (''' drop table if exists outflow_connects_to_channel ''')\n",
    "conn.execute (''' drop table if exists port ''')\n",
    "conn.execute (''' drop table if exists port_alias ''')\n",
    "conn.execute (''' drop table if exists port_connects_to_channel ''')\n",
    "conn.execute (''' drop table if exists steps ''')\n",
    "conn.execute (''' drop table if exists workflow ''')\n",
    "conn.execute (''' drop table if exists cwl_steps_info ''')\n",
    "conn.execute (''' drop table if exists wf_ports ''')\n",
    "conn.execute (''' drop table if exists qual_portname ''')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x10e78df10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create tables for storing the data model. \n",
    "\n",
    "\n",
    "\n",
    "# % FACT: program(program_id, program_name, qualified_program_name, begin_annotation_id, end_annotation_id).\n",
    "conn.execute(\"\"\"create table steps (\n",
    "                program_id      int     primary key not NULL ,\n",
    "                program_name      text,\n",
    "                qualified_program_name  text)\n",
    "            \"\"\")\n",
    "\n",
    "#% FACT: workflow(program_id).\n",
    "\n",
    "conn.execute(\"\"\"create table workflow (\n",
    "                program_id      int\n",
    "                )\n",
    "            \"\"\")\n",
    "\n",
    "#% FACT: has_subprogram(program_id, subprogram_id).\n",
    "\n",
    "conn.execute(\"\"\"create table has_subprogram (\n",
    "                program_id  int,\n",
    "                sub_program_id      int\n",
    "                )\n",
    "            \"\"\")\n",
    "\n",
    "#% FACT: port(port_id, port_type, port_name, qualified_port_name, port_annotation_id, data_id).\n",
    "\n",
    "\n",
    "conn.execute(\"\"\"create table port (\n",
    "                port_id      int     primary key not NULL,\n",
    "                port_type  int,\n",
    "                port_name  text,\n",
    "                qualified_port_name text,\n",
    "                port_annotation_id int, \n",
    "                data_id int \n",
    "                )\n",
    "            \"\"\")\n",
    "\n",
    "\n",
    "\n",
    "# % FACT: port_alias(port_id, alias).\n",
    "\n",
    "conn.execute(\"\"\"create table port_alias (\n",
    "                port_id    int  ,\n",
    "                alias    text\n",
    "                )\n",
    "            \"\"\")\n",
    "\n",
    "#% FACT: has_in_port(block_id, port_id).\n",
    "\n",
    "conn.execute(\"\"\"create table has_in_port (\n",
    "                block_id int,\n",
    "                port_id    int\n",
    "                )\n",
    "            \"\"\")\n",
    "\n",
    "#% FACT: has_out_port(block_id, port_id).\n",
    "\n",
    "conn.execute(\"\"\"create table has_out_port (\n",
    "                block_id int,\n",
    "                port_id    int\n",
    "                )\n",
    "            \"\"\")\n",
    "\n",
    "#% FACT: data(data_id, data_name, qualified_data_name).\n",
    "\n",
    "conn.execute(\"\"\"create table data (\n",
    "                data_id int,\n",
    "                data_name    text,\n",
    "                qualified_data_name text\n",
    "                )\n",
    "            \"\"\")\n",
    "\n",
    "#% FACT: channel(channel_id, data_id).\n",
    "\n",
    "\n",
    "conn.execute(\"\"\"create table channel (\n",
    "                channel_id int,\n",
    "                data_id    int\n",
    "                )\n",
    "            \"\"\")\n",
    "\n",
    "#% FACT: port_connects_to_channel(port_id, channel_id).\n",
    "\n",
    "conn.execute(\"\"\"create table port_connects_to_channel (\n",
    "                port_id int,\n",
    "                channel_id    int\n",
    "                )\n",
    "            \"\"\")\n",
    "    \n",
    "# % FACT: inflow_connects_to_channel(port_id, channel_id).\n",
    "conn.execute(\"\"\"create table inflow_connects_to_channel (\n",
    "                port_id int,\n",
    "                channel_id    int\n",
    "                )\n",
    "            \"\"\")\n",
    "\n",
    "\n",
    "#% FACT: outflow_connects_to_channel(port_id, channel_id).\n",
    "conn.execute(\"\"\"create table outflow_connects_to_channel (\n",
    "                port_id int,\n",
    "                channel_id    int\n",
    "                )\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "read_yw_model(yw_model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql_steps_in_out_ports = '''\n",
    "select \n",
    "\twf.wf_id as workflow_id , s.program_id as program_id, s.program_name as program_name,\n",
    "\tp.port_name as port_name, p.qualified_port_name as qname, p.port_id as port_id, p.port_type as port_type , p.data_id as data_id   \n",
    "from \n",
    "\tsteps s, port p, has_in_port inp, \n",
    "\t(select \n",
    "\t\tsub_program_id  , program_id as wf_id \n",
    "\t from \n",
    "\t\thas_subprogram\n",
    "\t) wf\n",
    "where \n",
    "\ts.program_id = inp.block_id\n",
    "and\tp.port_id = inp.port_id \n",
    "and inp.block_id  = wf.sub_program_id\n",
    "union \n",
    "select \n",
    "\twf.wf_id as workflow_id , s.program_id as program_id, s.program_name as program_name,\n",
    "\tp.port_name as port_name,p.qualified_port_name as qname, p.port_id as port_id, p.port_type as port_type , p.data_id as data_id \n",
    "from \n",
    "\tsteps s, port p, has_out_port out,\n",
    "\t(select \n",
    "\t\tsub_program_id  , program_id as wf_id \n",
    "\t from \n",
    "\t\thas_subprogram\n",
    "\t) wf\n",
    "where \n",
    "\ts.program_id = out.block_id\n",
    "and\tp.port_id = out.port_id \n",
    "and out.block_id = wf.sub_program_id\n",
    "'''\n",
    "\n",
    "\n",
    "sql_wf_ports = '''\n",
    "select \n",
    "\ts.program_id, s.program_name, p.port_name, p.port_id, p.port_type, p.data_id  \n",
    "from \n",
    "\tsteps s, port p, has_in_port inp \n",
    "where \n",
    "\ts.program_id = inp.block_id\n",
    "and\tp.port_id = inp.port_id \n",
    "and inp.block_id in \n",
    "\t(select \n",
    "\t\tprogram_id  \n",
    "\t from \n",
    "\t\tworkflow\n",
    "\t)\n",
    "union \n",
    "select \n",
    "\ts.program_id, s.program_name, p.port_name,p.port_id, p.port_type , p.data_id\n",
    "from \n",
    "\tsteps s, port p, has_out_port out \n",
    "where \n",
    "\ts.program_id = out.block_id\n",
    "and\tp.port_id = out.port_id \n",
    "and out.block_id in \n",
    "\t(select \n",
    "\t\tprogram_id  \n",
    "\t from \n",
    "\t\tworkflow\n",
    "\t)\n",
    "'''\n",
    "\n",
    "sql_qual_portname = '''\n",
    "select \n",
    "\tdistinct p.program_id as workflow_id,  p.port_id,  p.program_name, p.port_name ,p.port_name as qualified_portname, p.port_type , p.data_id\n",
    "from\n",
    "\twf_ports p, inflow_connects_to_channel q\n",
    " where upper(p.port_type) in ('IN')\n",
    " and p.port_id = q.port_id\n",
    "union \n",
    "select\n",
    "\tp.workflow_id, p.port_id, p.program_name, p.port_name, p.program_name || '/' || p.port_name as qualified_portname, p.port_type , p.data_id\n",
    "from\n",
    "\tcwl_steps_info p\n",
    "where upper(p.port_type)= 'OUT'\n",
    "union\n",
    "select\n",
    "\tp.program_id as workflow_id, p.port_id, p.program_name, p.port_name, p.port_name as qualified_portname, p.port_type , p.data_id\n",
    "from\n",
    "\twf_ports p, port po\n",
    "where p.port_id = po.port_id \n",
    "and upper(po.port_name) like '_YW_IN%'\n",
    "'''\n",
    "\n",
    "sql_wf_qual_out_port = '''\n",
    "select \n",
    "\tp.program_name, q.port_name, p.program_name || '/' || p.port_name as qualified_portname, p.port_type , p.data_id\n",
    "from \n",
    "\tcwl_steps_info p , port q\n",
    "where q.port_id = p.port_id\n",
    "and p.port_id in \n",
    "\t(\n",
    "\tselect \n",
    "\t\tport_id\n",
    "\tfrom \n",
    "\t\tport_connects_to_channel\n",
    "\twhere \n",
    "\t\tchannel_id in \n",
    "\t\t(select \n",
    "\t\t\tmax(channel_id)\n",
    "\t\tfrom \n",
    "\t\t\toutflow_connects_to_channel\n",
    "\t\tgroup by port_id\n",
    "\t\t)\n",
    "\t)\n",
    "union \n",
    "select \n",
    "\tp.program_name, pa.alias as port_name, p.program_name || '/' || p.port_name as qualified_portname, p.port_type , p.data_id\n",
    "from \n",
    "\tcwl_steps_info p , port q, port_alias pa\n",
    "where q.port_id = p.port_id\n",
    "and p.port_id = pa.port_id\n",
    "and p.port_id in \n",
    "\t(\n",
    "\tselect \n",
    "\t\tport_id\n",
    "\tfrom \n",
    "\t\tport_connects_to_channel\n",
    "\twhere \n",
    "\t\tchannel_id in \n",
    "\t\t(select \n",
    "\t\t\tmax(channel_id)\n",
    "\t\tfrom \n",
    "\t\t\toutflow_connects_to_channel\n",
    "\t\tgroup by port_id\n",
    "\t\t)\n",
    "\t)\n",
    "union\n",
    "select \n",
    "\tp.qualified_port_name, p.port_name,  p.qualified_port_name, p.port_type , p.data_id\n",
    "from \n",
    "\tport p \n",
    "where p.port_name like '_YW_OUT%'\n",
    "'''\n",
    "\n",
    "sql_dangling_port_id = \"\"\"\n",
    "select \n",
    "\tport_id \n",
    "from\n",
    "\tport \n",
    "where data_id in \n",
    "(\n",
    "\tselect distinct data_id from port  \n",
    "\tEXCEPT\n",
    "\tselect distinct data_id  from channel\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "sql_port_alias = '''\n",
    "select \n",
    "    port_id, alias\n",
    "from \n",
    "    port_alias\n",
    "'''\n",
    "\n",
    "sql_multiwriter_port = '''\n",
    "select \n",
    "\tcwf.workflow_id as workflow_id , cwf.program_id as program_id, cwf.program_name as program_name,cwf.port_name as port_name, cwf.port_id as port_id, cwf.port_type as port_type , cwf.data_id as data_id \n",
    "from \n",
    "\tcwl_steps_info cwf\n",
    "where port_type = 'OUT'\n",
    "and cwf.data_id in \n",
    "\t(\n",
    "\tselect \n",
    "\t\tdata_id\n",
    "\tfrom \n",
    "\t\tcwl_steps_info\n",
    "\twhere port_type ='OUT'\n",
    "\tgroup by data_id\n",
    "\thaving count(1) > 1\n",
    "\t)\n",
    "'''\n",
    "#df_dangling_ports = pd.read_sql_query(sql_dangling_port_id, con=conn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x10e7f70a0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.execute('create table if not exists cwl_steps_info as ' + sql_steps_in_out_ports)\n",
    "#conn.execute('create table wf_ports as ' + sql_wf_ports)\n",
    "#conn.execute('create table qual_portname as ' + sql_qual_portname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cwl_file_df = pd.DataFrame()\n",
    "wf_port_df = pd.DataFrame()\n",
    "qual_portname = pd.DataFrame()\n",
    "qual_wf_out_port = pd.DataFrame()\n",
    "df_dangling_ports = pd.DataFrame()\n",
    "df_port_alias = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cwl_file_df = pd.read_sql_query(sql_steps_in_out_ports, con=conn)\n",
    "wf_port_df = pd.read_sql_query(sql_wf_ports, con=conn)\n",
    "df_dangling_ports = pd.read_sql_query(sql_dangling_port_id, con=conn)\n",
    "df_port_alias = pd.read_sql_query(sql_port_alias, con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Add an input port in the ports tables\n",
    "def ins_in_port(program_name):\n",
    "    wf_id = cwl_file_df[cwl_file_df['program_name'] == program_name]['workflow_id'].values[0]\n",
    "    prog_id = cwl_file_df[cwl_file_df['program_name'] == program_name]['program_id'].values[0]\n",
    "    port_id = cwl_file_df['port_id'].max() + 1\n",
    "    data_id = cwl_file_df['data_id'].max() + 1\n",
    "    #print(port_id, data_id)\n",
    "    port_type = 'IN'\n",
    "    port_name = '_YW_IN_'+ program_name\n",
    "    qual_prog_name = program_name + '/' + port_name\n",
    "    sql = \"\"\"\n",
    "    insert into port values (?,?,?,?,?,?)\n",
    "    \"\"\"\n",
    "    data = [int(port_id), port_type, port_name,port_name,port_id,int(data_id)]\n",
    "    conn.execute(sql,data)\n",
    "    \n",
    "    sql = \"\"\"\n",
    "    insert into has_in_port values (?,?)\n",
    "    \"\"\"\n",
    "    data = [int(wf_id),int(port_id)]\n",
    "    print(data)\n",
    "    conn.execute(sql,data)\n",
    "    data = [int(prog_id),int(port_id)]\n",
    "    print(data)    \n",
    "    conn.execute(sql,data)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Add an output port in the ports tables\n",
    "def ins_out_port(program_name):\n",
    "    wf_id = cwl_file_df[cwl_file_df['program_name'] == program_name]['workflow_id'].values[0]\n",
    "    prog_id = cwl_file_df[cwl_file_df['program_name'] == program_name]['program_id'].values[0]\n",
    "    port_id = cwl_file_df['port_id'].max() + 1\n",
    "    data_id = cwl_file_df['data_id'].max() + 1\n",
    "    #print(port_id, data_id)\n",
    "    port_type = 'OUT'\n",
    "    port_name = '_YW_OUT_'+ program_name\n",
    "    qual_prog_name = program_name + '/' + port_name\n",
    "    sql = \"\"\"\n",
    "    insert into port values (?,?,?,?,?,?)\n",
    "    \"\"\"\n",
    "    data = [int(port_id), port_type, port_name,qual_prog_name,port_id,int(data_id)]\n",
    "    conn.execute(sql,data)\n",
    "    \n",
    "    sql = \"\"\"\n",
    "    insert into has_out_port values (?,?)\n",
    "    \"\"\"\n",
    "    data = [int(wf_id),int(port_id)]\n",
    "    conn.execute(sql,data)\n",
    "    data = [int(prog_id),int(port_id)]\n",
    "    conn.execute(sql,data)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Add an output port in the ports tables\n",
    "def ins_link_wf_port(port_id, wf_id,port_type,program_name):\n",
    "    #print(port_id, data_id)\n",
    "    new_port_id = get_max_port_id() + 1\n",
    "    data_id = cwl_file_df[cwl_file_df['port_id'] == port_id]['data_id']\n",
    "    #print(type(new_port_id))\n",
    "    \n",
    "    port_name = cwl_file_df[cwl_file_df['port_id'] == port_id]['port_name'].values[0]\n",
    "    \n",
    "    print(port_name)\n",
    "    if port_type == 'OUT':\n",
    "        wf_port_name = '_YW_OUT_'+ port_name\n",
    "        qual_prog_name = program_name + '/' + port_name\n",
    "        sql_link = \"\"\"\n",
    "                   insert into has_out_port values (?,?)\n",
    "                   \"\"\"\n",
    "        values = [int(wf_id),int(new_port_id)]\n",
    "    else: \n",
    "        wf_port_name = '_YW_IN_'+ port_name\n",
    "        qual_prog_name =  wf_port_name\n",
    "        sql_link = \"\"\"\n",
    "                   insert into has_in_port values (?,?)\n",
    "                   \"\"\"   \n",
    "        values = [int(wf_id),int(new_port_id)]\n",
    "        \n",
    "    print(qual_prog_name)\n",
    "    sql = \"\"\"\n",
    "    insert into port values (?,?,?,?,?,?)\n",
    "    \"\"\"\n",
    "    \n",
    "    data = [int(new_port_id), port_type, wf_port_name,qual_prog_name,port_id,int(data_id)]\n",
    "    conn.execute(sql,data)\n",
    "    #print(data)\n",
    "    #print(values)\n",
    "    conn.execute(sql_link,values)\n",
    "    conn.commit()\n",
    "    \n",
    "    #rebuild_dataframes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_max_port_id():\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('''SELECT max(port_id) from port ''')\n",
    "    max_port_id = cur.fetchone()\n",
    "    \n",
    "    return int(max_port_id[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 39]\n",
      "[5, 39]\n"
     ]
    }
   ],
   "source": [
    "### Check for the programs without output ports\n",
    "### use the ins_out_port to create the output port for wf and prog. \n",
    "\n",
    "program_name_uniq = cwl_file_df['program_name'].unique()\n",
    "program_with_out  = cwl_file_df[cwl_file_df['port_type'] == 'OUT'][\"program_name\"].unique()\n",
    "prog_wo_outport = list(set(program_name_uniq).difference(set(program_with_out)))\n",
    "\n",
    "for prog in prog_wo_outport:\n",
    "    #print(prog)\n",
    "    ins_out_port(prog)\n",
    "\n",
    "\n",
    "program_with_in  = cwl_file_df[cwl_file_df['port_type'] == 'IN'][\"program_name\"].unique()\n",
    "prog_wo_inport  =list(set(program_name_uniq).difference(set(program_with_in)))\n",
    "\n",
    "for prog in prog_wo_inport: \n",
    "    #print(prog)\n",
    "    ins_in_port(prog)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for the dangling ports and create \n",
    "## the respective ports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the list of the dangling port id's and pass into the DF. \n",
    "for idx in cwl_file_df[cwl_file_df['port_id'].isin(df_dangling_ports['port_id'])].index:\n",
    "    wf_id = cwl_file_df.loc[idx]['workflow_id']\n",
    "    port_id = cwl_file_df.loc[idx]['port_id']\n",
    "    port_type = cwl_file_df.loc[idx]['port_type']\n",
    "    program_name = cwl_file_df.loc[idx]['program_name']\n",
    "    ins_link_wf_port(port_id, wf_id,port_type,program_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reload the dataframes now \n",
    "\n",
    "conn.execute (''' drop table if exists cwl_steps_info ''')\n",
    "conn.execute (''' drop table if exists wf_ports ''')\n",
    "conn.execute (''' drop table if exists qual_portname ''')\n",
    "\n",
    "conn.execute('create table if not exists cwl_steps_info as ' + sql_steps_in_out_ports)\n",
    "conn.execute('create table if not exists wf_ports as ' + sql_wf_ports)\n",
    "conn.execute('create table if not exists qual_portname as ' + sql_qual_portname)\n",
    "conn.execute('create table if not exists qual_portname as ' + sql_qual_portname)\n",
    "\n",
    "cwl_file_df = pd.read_sql_query(sql_steps_in_out_ports, con=conn)\n",
    "wf_port_df = pd.read_sql_query(sql_wf_ports, con=conn)\n",
    "qual_portname = pd.read_sql_query(sql_qual_portname, con=conn)\n",
    "qual_wf_out_port = pd.read_sql_query(sql_wf_qual_out_port, con=conn)\n",
    "df_dangling_ports = pd.read_sql_query(sql_dangling_port_id, con=conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workflow_id</th>\n",
       "      <th>port_id</th>\n",
       "      <th>program_name</th>\n",
       "      <th>port_name</th>\n",
       "      <th>qualified_portname</th>\n",
       "      <th>port_type</th>\n",
       "      <th>data_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C3_C4_map_present_NA</td>\n",
       "      <td>SYNMAP_land_cover_map_data</td>\n",
       "      <td>SYNMAP_land_cover_map_data</td>\n",
       "      <td>IN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>C3_C4_map_present_NA</td>\n",
       "      <td>mean_airtemp</td>\n",
       "      <td>mean_airtemp</td>\n",
       "      <td>IN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>C3_C4_map_present_NA</td>\n",
       "      <td>mean_precip</td>\n",
       "      <td>mean_precip</td>\n",
       "      <td>IN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>fetch_SYNMAP_land_cover_map_variable</td>\n",
       "      <td>lon</td>\n",
       "      <td>fetch_SYNMAP_land_cover_map_variable/lon</td>\n",
       "      <td>OUT</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>fetch_SYNMAP_land_cover_map_variable</td>\n",
       "      <td>lat</td>\n",
       "      <td>fetch_SYNMAP_land_cover_map_variable/lat</td>\n",
       "      <td>OUT</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>fetch_SYNMAP_land_cover_map_variable</td>\n",
       "      <td>lon_bnds</td>\n",
       "      <td>fetch_SYNMAP_land_cover_map_variable/lon_bnds</td>\n",
       "      <td>OUT</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>fetch_SYNMAP_land_cover_map_variable</td>\n",
       "      <td>lat_bnds</td>\n",
       "      <td>fetch_SYNMAP_land_cover_map_variable/lat_bnds</td>\n",
       "      <td>OUT</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>fetch_monthly_mean_air_temperature_data</td>\n",
       "      <td>Tair</td>\n",
       "      <td>fetch_monthly_mean_air_temperature_data/Tair</td>\n",
       "      <td>OUT</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>fetch_monthly_mean_precipitation_data</td>\n",
       "      <td>Rain</td>\n",
       "      <td>fetch_monthly_mean_precipitation_data/Rain</td>\n",
       "      <td>OUT</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>initialize_Grass_Matrix</td>\n",
       "      <td>Grass</td>\n",
       "      <td>initialize_Grass_Matrix/Grass</td>\n",
       "      <td>OUT</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>examine_pixels_for_grass</td>\n",
       "      <td>C3</td>\n",
       "      <td>examine_pixels_for_grass/C3</td>\n",
       "      <td>OUT</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>examine_pixels_for_grass</td>\n",
       "      <td>C4</td>\n",
       "      <td>examine_pixels_for_grass/C4</td>\n",
       "      <td>OUT</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>generate_netcdf_file_for_C3_fraction</td>\n",
       "      <td>C3_fraction_data</td>\n",
       "      <td>generate_netcdf_file_for_C3_fraction/C3_fracti...</td>\n",
       "      <td>OUT</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>generate_netcdf_file_for_C4_fraction</td>\n",
       "      <td>C4_fraction_data</td>\n",
       "      <td>generate_netcdf_file_for_C4_fraction/C4_fracti...</td>\n",
       "      <td>OUT</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>generate_netcdf_file_for_Grass_fraction</td>\n",
       "      <td>Grass_fraction_data</td>\n",
       "      <td>generate_netcdf_file_for_Grass_fraction/Grass_...</td>\n",
       "      <td>OUT</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>C3_C4_map_present_NA</td>\n",
       "      <td>_YW_IN_initialize_Grass_Matrix</td>\n",
       "      <td>_YW_IN_initialize_Grass_Matrix</td>\n",
       "      <td>IN</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    workflow_id  port_id                             program_name  \\\n",
       "0             1        1                     C3_C4_map_present_NA   \n",
       "1             1        2                     C3_C4_map_present_NA   \n",
       "2             1        3                     C3_C4_map_present_NA   \n",
       "3             1        8     fetch_SYNMAP_land_cover_map_variable   \n",
       "4             1        9     fetch_SYNMAP_land_cover_map_variable   \n",
       "5             1       10     fetch_SYNMAP_land_cover_map_variable   \n",
       "6             1       11     fetch_SYNMAP_land_cover_map_variable   \n",
       "7             1       13  fetch_monthly_mean_air_temperature_data   \n",
       "8             1       15    fetch_monthly_mean_precipitation_data   \n",
       "9             1       16                  initialize_Grass_Matrix   \n",
       "10            1       19                 examine_pixels_for_grass   \n",
       "11            1       20                 examine_pixels_for_grass   \n",
       "12            1       26     generate_netcdf_file_for_C3_fraction   \n",
       "13            1       32     generate_netcdf_file_for_C4_fraction   \n",
       "14            1       38  generate_netcdf_file_for_Grass_fraction   \n",
       "15            1       39                     C3_C4_map_present_NA   \n",
       "\n",
       "                         port_name  \\\n",
       "0       SYNMAP_land_cover_map_data   \n",
       "1                     mean_airtemp   \n",
       "2                      mean_precip   \n",
       "3                              lon   \n",
       "4                              lat   \n",
       "5                         lon_bnds   \n",
       "6                         lat_bnds   \n",
       "7                             Tair   \n",
       "8                             Rain   \n",
       "9                            Grass   \n",
       "10                              C3   \n",
       "11                              C4   \n",
       "12                C3_fraction_data   \n",
       "13                C4_fraction_data   \n",
       "14             Grass_fraction_data   \n",
       "15  _YW_IN_initialize_Grass_Matrix   \n",
       "\n",
       "                                   qualified_portname port_type  data_id  \n",
       "0                          SYNMAP_land_cover_map_data        IN        1  \n",
       "1                                        mean_airtemp        IN        2  \n",
       "2                                         mean_precip        IN        3  \n",
       "3            fetch_SYNMAP_land_cover_map_variable/lon       OUT        8  \n",
       "4            fetch_SYNMAP_land_cover_map_variable/lat       OUT        9  \n",
       "5       fetch_SYNMAP_land_cover_map_variable/lon_bnds       OUT       10  \n",
       "6       fetch_SYNMAP_land_cover_map_variable/lat_bnds       OUT       11  \n",
       "7        fetch_monthly_mean_air_temperature_data/Tair       OUT       13  \n",
       "8          fetch_monthly_mean_precipitation_data/Rain       OUT       15  \n",
       "9                       initialize_Grass_Matrix/Grass       OUT       16  \n",
       "10                        examine_pixels_for_grass/C3       OUT       17  \n",
       "11                        examine_pixels_for_grass/C4       OUT       18  \n",
       "12  generate_netcdf_file_for_C3_fraction/C3_fracti...       OUT       19  \n",
       "13  generate_netcdf_file_for_C4_fraction/C4_fracti...       OUT       20  \n",
       "14  generate_netcdf_file_for_Grass_fraction/Grass_...       OUT       21  \n",
       "15                     _YW_IN_initialize_Grass_Matrix        IN       22  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qual_portname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_filename(program_id, is_wf):\n",
    "    wfid_list = wf_port_df['program_id'].unique()\n",
    "    if is_wf:\n",
    "        program_name =wf_port_df[wf_port_df['program_id'] ==program_id]['program_name'].values[0]\n",
    "        return 'wf_' + program_name + '.cwl'\n",
    "    elif program_id in wfid_list:      \n",
    "        program_name = cwl_file_df[cwl_file_df['program_id'] ==program_id]['program_name'].values[0]\n",
    "        return 'wf_' + program_name + '.cwl'\n",
    "    else:\n",
    "        program_name = cwl_file_df[cwl_file_df['program_id'] ==program_id]['program_name'].values[0]\n",
    "        return program_name + '.cwl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_cwl_file(filename, header, input_params, output_params):\n",
    "    #print(filename)\n",
    "    with open(filename,'w+') as writer: \n",
    "        writer.write(header)\n",
    "        writer.write(input_params)\n",
    "        writer.write(output_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_wf_steps(workflow_id):\n",
    "    header_step = \"steps: \\n \"\n",
    "    buffer=''\n",
    "    prog_list = cwl_file_df[cwl_file_df['workflow_id'] == workflow_id]['program_id'].unique()\n",
    "    \n",
    "    for prog in prog_list: \n",
    "        outport_list= []\n",
    "        prog_name = cwl_file_df[cwl_file_df['program_id'] ==prog]['program_name'].values[0]\n",
    "        filename = get_filename(prog,False)\n",
    "        \n",
    "\n",
    "\n",
    "        buffer = buffer + prog_name + ': \\n ' + ' run: ' +filename + ' \\n ' + ' in: \\n'\n",
    "        \n",
    "        for pid in cwl_file_df[cwl_file_df[\"program_id\"]==prog].index:\n",
    "            \n",
    "            port_id = cwl_file_df.loc[pid]['port_id'] \n",
    "            port_name = cwl_file_df.loc[pid]['port_name'] \n",
    "            port_type = cwl_file_df.loc[pid]['port_type']       \n",
    "            data_id = cwl_file_df.loc[pid]['data_id']\n",
    "            \n",
    "            if port_type == 'IN':\n",
    "                \n",
    "                filtered_df =  qual_portname[qual_portname[\"workflow_id\"] == workflow_id]\n",
    "                qn_df = filtered_df[filtered_df[\"data_id\"] == data_id][\"qualified_portname\"]\n",
    "                \n",
    "                if len(qn_df) == 0 :\n",
    "                    alias = df_port_alias[df_port_alias[\"port_id\"]==port_id]['alias']\n",
    "                    wf_in_port = wf_port_df[wf_port_df[\"port_name\"] ==port_name].values[0] \n",
    "                    if len(wf_in_port) != 0:\n",
    "                        qname = port_name                   \n",
    "                    elif len(alias) != 0 :\n",
    "                        #print(qn_df)\n",
    "                        #print(alias)\n",
    "                        qname = alias.values[0]\n",
    "                    else:\n",
    "                        qname = port_name\n",
    "                else: \n",
    "                    if '_YW_IN_' in port_name:\n",
    "                        qname = cwl_file_df.loc[pid]['qname']\n",
    "                    else:\n",
    "                        qname = qn_df.values[0]\n",
    "                buffer = buffer + '   ' + port_name + ': ' + qname + '\\n'\n",
    "            else: \n",
    "                outport_list.append(port_name)\n",
    "            #break\n",
    "        buffer = buffer + \"  out: [\" + ','.join(outport_list) + '] \\n '    \n",
    "    \n",
    "    return header_step + buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps: \n",
      " fetch_SYNMAP_land_cover_map_variable: \n",
      "  run: fetch_SYNMAP_land_cover_map_variable.cwl \n",
      "  in: \n",
      "   SYNMAP_land_cover_map_data: SYNMAP_land_cover_map_data\n",
      "  out: [lat,lat_bnds,lon,lon_bnds] \n",
      " fetch_monthly_mean_air_temperature_data: \n",
      "  run: fetch_monthly_mean_air_temperature_data.cwl \n",
      "  in: \n",
      "   mean_airtemp: mean_airtemp\n",
      "  out: [Tair] \n",
      " fetch_monthly_mean_precipitation_data: \n",
      "  run: fetch_monthly_mean_precipitation_data.cwl \n",
      "  in: \n",
      "   mean_precip: mean_precip\n",
      "  out: [Rain] \n",
      " initialize_Grass_Matrix: \n",
      "  run: initialize_Grass_Matrix.cwl \n",
      "  in: \n",
      "   _YW_IN_initialize_Grass_Matrix: initialize_Grass_Matrix/_YW_IN_initialize_Grass_Matrix\n",
      "  out: [Grass] \n",
      " examine_pixels_for_grass: \n",
      "  run: examine_pixels_for_grass.cwl \n",
      "  in: \n",
      "   Rain: fetch_monthly_mean_precipitation_data/Rain\n",
      "   Tair: fetch_monthly_mean_air_temperature_data/Tair\n",
      "  out: [C3,C4] \n",
      " generate_netcdf_file_for_C3_fraction: \n",
      "  run: generate_netcdf_file_for_C3_fraction.cwl \n",
      "  in: \n",
      "   C3_Data: examine_pixels_for_grass/C3\n",
      "   lat_bnds_variable: fetch_SYNMAP_land_cover_map_variable/lat_bnds\n",
      "   lat_variable: fetch_SYNMAP_land_cover_map_variable/lat\n",
      "   lon_bnds_variable: fetch_SYNMAP_land_cover_map_variable/lon_bnds\n",
      "   lon_variable: fetch_SYNMAP_land_cover_map_variable/lon\n",
      "  out: [C3_fraction_data] \n",
      " generate_netcdf_file_for_C4_fraction: \n",
      "  run: generate_netcdf_file_for_C4_fraction.cwl \n",
      "  in: \n",
      "   C4_Data: examine_pixels_for_grass/C4\n",
      "   lat_bnds_variable: fetch_SYNMAP_land_cover_map_variable/lat_bnds\n",
      "   lat_variable: fetch_SYNMAP_land_cover_map_variable/lat\n",
      "   lon_bnds_variable: fetch_SYNMAP_land_cover_map_variable/lon_bnds\n",
      "   lon_variable: fetch_SYNMAP_land_cover_map_variable/lon\n",
      "  out: [C4_fraction_data] \n",
      " generate_netcdf_file_for_Grass_fraction: \n",
      "  run: generate_netcdf_file_for_Grass_fraction.cwl \n",
      "  in: \n",
      "   Grass_variable: initialize_Grass_Matrix/Grass\n",
      "   lat_bnds_variable: fetch_SYNMAP_land_cover_map_variable/lat_bnds\n",
      "   lat_variable: fetch_SYNMAP_land_cover_map_variable/lat\n",
      "   lon_bnds_variable: fetch_SYNMAP_land_cover_map_variable/lon_bnds\n",
      "   lon_variable: fetch_SYNMAP_land_cover_map_variable/lon\n",
      "  out: [Grass_fraction_data] \n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(get_wf_steps(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## creating the cwl files and the wf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wf_id = cwl_file_df['workflow_id'].unique()\n",
    "prog_list = cwl_file_df['program_id'].unique()\n",
    "dirname = 'example_sql/' + wf_port_df[wf_port_df[\"program_id\"] ==1]['program_name'].values[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetch_SYNMAP_land_cover_map_variable\n",
      "SYNMAP_land_cover_map_data IN\n",
      "fetch_SYNMAP_land_cover_map_variable\n",
      "lat OUT\n",
      "fetch_SYNMAP_land_cover_map_variable\n",
      "lat_bnds OUT\n",
      "fetch_SYNMAP_land_cover_map_variable\n",
      "lon OUT\n",
      "fetch_SYNMAP_land_cover_map_variable\n",
      "lon_bnds OUT\n",
      "fetch_monthly_mean_air_temperature_data\n",
      "Tair OUT\n",
      "fetch_monthly_mean_air_temperature_data\n",
      "mean_airtemp IN\n",
      "fetch_monthly_mean_precipitation_data\n",
      "Rain OUT\n",
      "fetch_monthly_mean_precipitation_data\n",
      "mean_precip IN\n",
      "initialize_Grass_Matrix\n",
      "Grass OUT\n",
      "initialize_Grass_Matrix\n",
      "_YW_IN_initialize_Grass_Matrix IN\n",
      "examine_pixels_for_grass\n",
      "C3 OUT\n",
      "examine_pixels_for_grass\n",
      "C4 OUT\n",
      "examine_pixels_for_grass\n",
      "Rain IN\n",
      "examine_pixels_for_grass\n",
      "Tair IN\n",
      "generate_netcdf_file_for_C3_fraction\n",
      "C3_Data IN\n",
      "generate_netcdf_file_for_C3_fraction\n",
      "C3_fraction_data OUT\n",
      "generate_netcdf_file_for_C3_fraction\n",
      "lat_bnds_variable IN\n",
      "generate_netcdf_file_for_C3_fraction\n",
      "lat_variable IN\n",
      "generate_netcdf_file_for_C3_fraction\n",
      "lon_bnds_variable IN\n",
      "generate_netcdf_file_for_C3_fraction\n",
      "lon_variable IN\n",
      "generate_netcdf_file_for_C4_fraction\n",
      "C4_Data IN\n",
      "generate_netcdf_file_for_C4_fraction\n",
      "C4_fraction_data OUT\n",
      "generate_netcdf_file_for_C4_fraction\n",
      "lat_bnds_variable IN\n",
      "generate_netcdf_file_for_C4_fraction\n",
      "lat_variable IN\n",
      "generate_netcdf_file_for_C4_fraction\n",
      "lon_bnds_variable IN\n",
      "generate_netcdf_file_for_C4_fraction\n",
      "lon_variable IN\n",
      "generate_netcdf_file_for_Grass_fraction\n",
      "Grass_fraction_data OUT\n",
      "generate_netcdf_file_for_Grass_fraction\n",
      "Grass_variable IN\n",
      "generate_netcdf_file_for_Grass_fraction\n",
      "lat_bnds_variable IN\n",
      "generate_netcdf_file_for_Grass_fraction\n",
      "lat_variable IN\n",
      "generate_netcdf_file_for_Grass_fraction\n",
      "lon_bnds_variable IN\n",
      "generate_netcdf_file_for_Grass_fraction\n",
      "lon_variable IN\n"
     ]
    }
   ],
   "source": [
    "for prog_id in prog_list: \n",
    "\n",
    "    cwl_file_header = '''\n",
    "#!/usr/bin/env cwl-runner\n",
    "cwlVersion: v1.0\n",
    "class: CommandLineTool\n",
    "'''\n",
    "    input_buffer = 'inputs: \\n'\n",
    "    output_buffer = 'outputs: \\n'\n",
    "    \n",
    "    pname = cwl_file_df[cwl_file_df[\"program_id\"] == [prog_id]]['program_name'].values[0]\n",
    "    #print(prog_id)\n",
    "    filename = dirname + '/' + get_filename(prog_id, False)\n",
    "\n",
    "    #print(filename)\n",
    "    for p_idx in cwl_file_df[cwl_file_df[\"program_id\"] == [prog_id]].index:\n",
    "        #pname = cwl_file_df.loc[p_idx]['program_name']\n",
    "        pid = cwl_file_df.loc[p_idx]['program_id']\n",
    "        print(pname)\n",
    "        port_name = cwl_file_df.loc[p_idx]['port_name'] \n",
    "        port_type = cwl_file_df.loc[p_idx]['port_type'] \n",
    "        print(port_name, port_type)\n",
    "\n",
    "        if port_type == 'IN':\n",
    "            input_buffer = input_buffer + ' '+ port_name + ': \\n'+ '  type: string \\n \\n'\n",
    "            #print(input_buffer)\n",
    "        else: \n",
    "            output_buffer = output_buffer + ' '+ port_name + ': \\n'+ '  type: string \\n \\n'\n",
    "            #print(output_buffer)\n",
    "    \n",
    "    output_buffer = output_buffer + \"baseCommand: \"\n",
    "    write_cwl_file(filename, cwl_file_header, input_buffer, output_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C3_fraction_data\n",
      "C4_fraction_data\n",
      "Grass_fraction_data\n"
     ]
    }
   ],
   "source": [
    "cwl_wf_header = '''\n",
    "#!/usr/bin/env cwl-runner\n",
    "cwlVersion: v1.0\n",
    "class: Workflow\n",
    "requirements:\n",
    "    - class: SubworkflowFeatureRequirement\n",
    "\n",
    "'''\n",
    "workflow_list = wf_port_df['program_id'].unique()\n",
    "\n",
    "for id in sorted(workflow_list, reverse=True):\n",
    "    input_buffer = 'inputs: \\n'\n",
    "    output_buffer = 'outputs: \\n'\n",
    "    #print(id)\n",
    "    wf_name = wf_port_df[wf_port_df['program_id']== id][\"program_name\"].values[0]\n",
    "    filename= dirname +'/' + get_filename(id, True)\n",
    "    #print(filename)\n",
    "    for p_id in wf_port_df[wf_port_df['program_id']== id].index:\n",
    "        prog_id = wf_port_df.loc[p_id]['program_id']\n",
    "        #print(int(prog_id))\n",
    "\n",
    "\n",
    "        pname = wf_port_df.loc[p_id]['program_name']\n",
    "        port_name = wf_port_df.loc[p_id]['port_name'] \n",
    "        port_type = wf_port_df.loc[p_id]['port_type'] \n",
    "        data_id = wf_port_df.loc[p_id]['data_id'] \n",
    "\n",
    "\n",
    "        if port_type == 'IN':\n",
    "            input_buffer = input_buffer + ' '+ port_name + ': \\n'+ '  type: string \\n \\n'\n",
    "            #print(input_buffer)\n",
    "        else: \n",
    "            print(port_name)\n",
    "            qn_df = qual_wf_out_port[qual_wf_out_port['port_name'] == port_name]\n",
    "            #print(qn_df)\n",
    "            if qn_df.shape[0] > 1:\n",
    "                print(qn_df['qualified_portname'].values[0])\n",
    "            else:\n",
    "                qname = qn_df['qualified_portname'].values[0]\n",
    "            output_buffer = output_buffer + '  ' +  port_name  + ': \\n' + '   type: string \\n   outputSource: '+ qname +'\\n'\n",
    "            #print(output_buffer)\n",
    "    \n",
    "    wf_step_contents = get_wf_steps(id)\n",
    "    write_cwl_file(filename,cwl_wf_header + input_buffer, output_buffer, wf_step_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_max_prog_id():\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('''SELECT max(program_id) as max_program_id from steps ''')\n",
    "    max_program_id = cur.fetchone()\n",
    "    \n",
    "    return int(max_program_id[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_max_outport_channel_id(port_id):\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(''' select \n",
    "\t\t\tmax(channel_id)\n",
    "\t\tfrom \n",
    "\t\t\toutflow_connects_to_channel\n",
    "        where port_id = :port_id\n",
    "\t\tgroup by port_id\n",
    "        ''', {'port_id':port_id})\n",
    "    max_channel_id = cur.fetchone()\n",
    "    \n",
    "    return int(max_channel_id[0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_max_outport_channel_id(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add an output port in the ports tables\n",
    "def ins_yw_program(wf_id, data_id,multiport_id, multi_port_name):\n",
    "    prog_id = get_max_prog_id() + 1\n",
    "    yw_prog_name = '_YW_PROG_' + str(prog_id )\n",
    "    \n",
    "    sql_prog = \"\"\"\n",
    "               insert into steps values(?,?,?) \n",
    "               \"\"\"\n",
    "\n",
    "    #print([prog_id, yw_prog_name, yw_prog_name])\n",
    "    \n",
    "    sql_inprog = \"\"\"\n",
    "                 insert into has_subprogram values(?,?)\n",
    "                 \"\"\"   \n",
    "    values = [int(wf_id), prog_id]\n",
    "    #print(values)\n",
    "    conn.execute(sql_prog,[prog_id, yw_prog_name, yw_prog_name])\n",
    "    conn.commit()\n",
    "    conn.execute(sql_inprog,values)\n",
    "    conn.commit()\n",
    "    \n",
    "    port_type = 'OUT'\n",
    "    new_port_id = get_max_port_id() +1 \n",
    "    wf_port_name = '_YW_OUT' + yw_prog_name\n",
    "    \n",
    "    sql_port = \"\"\"\n",
    "               insert into port values (?,?,?,?,?,?)\n",
    "               \"\"\" \n",
    "    data = [int(new_port_id), port_type, wf_port_name,yw_prog_name + '/'+ wf_port_name,new_port_id,int(data_id)]\n",
    "    \n",
    "    conn.execute(sql_port,data)\n",
    "    conn.commit()\n",
    "\n",
    "    sql_link = \"\"\"\n",
    "               insert into has_out_port values (?,?)\n",
    "               \"\"\"   \n",
    "    values = [int(prog_id),int(new_port_id)]\n",
    "    #print(values)\n",
    "    \n",
    "    conn.execute(sql_link,values)\n",
    "    conn.commit()       \n",
    "    \n",
    "    channel_id = get_max_outport_channel_id(int(multiport_id))\n",
    "    sql_upd = \"\"\"\n",
    "              update port_connects_to_channel set port_id = :port_id where channel_id =:channel_id\n",
    "              \"\"\"\n",
    "    conn.execute(sql_upd,  {\"channel_id\": channel_id, \"port_id\":new_port_id})\n",
    "    conn.commit()\n",
    "    \n",
    "    sql_link = \"\"\"\n",
    "               insert into port_alias values (?,?)\n",
    "               \"\"\"   \n",
    "    values = [int(new_port_id),multi_port_name]\n",
    "    conn.execute(sql_link,values)\n",
    "    conn.commit()       \n",
    "    \n",
    "    return prog_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Add an output port in the ports tables\n",
    "def ins_yw_prog_ports(new_program_id, port_id,port_name, qual_prog_name, data_id):\n",
    "    \n",
    "    port_type = 'IN'\n",
    "    new_port_id = get_max_port_id() +1 \n",
    "    wf_port_name = '_YW_IN_' + port_name + '_' + str(new_port_id)\n",
    "    \n",
    "    sql_port = \"\"\"\n",
    "               insert into port values (?,?,?,?,?,?)\n",
    "               \"\"\" \n",
    "    data = [int(new_port_id), port_type, wf_port_name,qual_prog_name,port_id,int(data_id)]\n",
    "    \n",
    "    conn.execute(sql_port,data)\n",
    "    conn.commit()\n",
    "\n",
    "    sql_link = \"\"\"\n",
    "               insert into has_in_port values (?,?)\n",
    "               \"\"\"   \n",
    "    values = [int(new_program_id),int(new_port_id)]\n",
    "    print(values)\n",
    "    \n",
    "    conn.execute(sql_link,values)\n",
    "    conn.commit()\n",
    "    \n",
    "    #rebuild_dataframes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_data = \"\"\"\n",
    "select \n",
    "    * \n",
    "from \n",
    "    data\n",
    "\"\"\"\n",
    "df_multiwriter_port= pd.read_sql_query(sql_multiwriter_port, con=conn)\n",
    "df_data= pd.read_sql_query(sql_data, con=conn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_multiwriter_port.shape[0] > 1: \n",
    "    wf_id = df_multiwriter_port['workflow_id'].values[0]\n",
    "    data_id = df_multiwriter_port['data_id'].values[0]\n",
    "    \n",
    "    #print(data_id)\n",
    "    multiport_name = df_data[df_data['data_id' ]== data_id]['data_name'].unique()[0]\n",
    "    #print(data_id,multiport_name)\n",
    "    multiport_id = wf_port_df[wf_port_df['port_name'] ==multiport_name][\"port_id\"].values[0]\n",
    "    wf_data_id = wf_port_df[wf_port_df['port_name'] == multiport_name]['data_id'].values[0]\n",
    "    print(data_id,multiport_name,multiport_id)\n",
    "    new_prog_id = ins_yw_program(wf_id,wf_data_id,multiport_id,multiport_name)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_prog_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-a658e53277b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_prog_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_multiwriter_port\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mport_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_multiwriter_port\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'port_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mport_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_multiwriter_port\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'port_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mport_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_multiwriter_port\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'port_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_prog_id' is not defined"
     ]
    }
   ],
   "source": [
    "print(new_prog_id)\n",
    "for idx in df_multiwriter_port.index:\n",
    "    port_id = df_multiwriter_port.loc[idx]['port_id']\n",
    "    port_name = df_multiwriter_port.loc[idx]['port_name']    \n",
    "    port_type = df_multiwriter_port.loc[idx]['port_type']\n",
    "    program_name = df_multiwriter_port.loc[idx]['program_name']\n",
    "    data_id = df_multiwriter_port.loc[idx]['data_id']\n",
    "\n",
    "    ins_yw_prog_ports(new_prog_id,port_id,port_name, program_name+'/'+port_name, data_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wf_id = df_multiwriter_port['workflow_id'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cwl_file_df = pd.read_sql_query(sql_steps_in_out_ports, con=conn)\n",
    "wf_port_df = pd.read_sql_query(sql_wf_ports, con=conn)\n",
    "qual_portname = pd.read_sql_query(sql_qual_portname, con=conn)\n",
    "qual_wf_out_port = pd.read_sql_query(sql_wf_qual_out_port, con=conn)\n",
    "df_dangling_ports = pd.read_sql_query(sql_dangling_port_id, con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual_wf_out_port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Reload the dataframes now \n",
    "\n",
    "conn.execute (''' drop table if exists cwl_steps_info ''')\n",
    "conn.execute (''' drop table if exists wf_ports ''')\n",
    "conn.execute (''' drop table if exists qual_portname ''')\n",
    "\n",
    "conn.execute('create table if not exists cwl_steps_info as ' + sql_steps_in_out_ports)\n",
    "conn.execute('create table if not exists wf_ports as ' + sql_wf_ports)\n",
    "conn.execute('create table if not exists qual_portname as ' + sql_qual_portname)\n",
    "\n",
    "\n",
    "cwl_file_df = pd.read_sql_query(sql_steps_in_out_ports, con=conn)\n",
    "wf_port_df = pd.read_sql_query(sql_wf_ports, con=conn)\n",
    "qual_portname = pd.read_sql_query(sql_qual_portname, con=conn)\n",
    "qual_wf_out_port = pd.read_sql_query(sql_wf_qual_out_port, con=conn)\n",
    "df_dangling_ports = pd.read_sql_query(sql_dangling_port_id, con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwl_file_df['program_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
