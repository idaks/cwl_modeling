{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import sqlite3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yw_model_file = \"example_sql/simulate_data_collection/simulate_data_collection.P\"\n",
    "\n",
    "db_model = yw_model_file[:-2] + '.db'\n",
    "#print(db_model)\n",
    "conn = sqlite3.connect(db_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for parsing the yw models file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### function extracting the programs.\n",
    "\n",
    "def extract_steps(line):\n",
    "    \n",
    "    #% FACT: program(program_id, program_name, qualified_program_name, begin_annotation_id, end_annotation_id).\n",
    "    #print(\"Extracting steps.\")\n",
    "    ## Extract data between \"(\" and \")\".\n",
    "    data = line[line.index(\"(\")+1:line.index(\")\")]\n",
    "    \n",
    "    data = data.split(',')\n",
    "    #print(data)\n",
    "    \n",
    "    \n",
    "    ins_query = [data[0].strip().strip(\"'\"),data[1].strip().strip(\"'\"),data[2].strip().strip(\"'\")]\n",
    "    conn.execute(\"\"\"insert into steps values(?,?,?)\"\"\", ins_query)\n",
    "    conn.commit()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### function extracting the workflow.\n",
    "\n",
    "def extract_workflows(line):\n",
    "    \n",
    "    #print(line)\n",
    "    data = line[line.index(\"(\")+1:line.index(\")\")]\n",
    "    #print(data)\n",
    "    conn.execute(\"\"\"insert into workflow values(?)\"\"\", data[0].strip().strip(\"'\"))\n",
    "    conn.commit()\n",
    "      \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### function extracting the ports\n",
    "\n",
    "def extract_ports(line):\n",
    "    #print(\"Extracting ports.\")\n",
    "    ## Extract data between \"(\" and \")\".\n",
    "    data = line[line.index(\"(\")+1:line.index(\")\")]\n",
    "    \n",
    "    #% FACT: port(port_id, port_type, port_name, qualified_port_name, port_annotation_id, data_id).\n",
    "    \n",
    "    data = data.split(',')\n",
    "    \n",
    "    if data[1].strip().strip(\"'\").upper().strip('\"') == 'PARAM':\n",
    "        port_type = 'IN'\n",
    "    else:\n",
    "        port_type = data[1].strip().strip(\"'\").upper().strip('\"')\n",
    "    \n",
    "    ins_query = [data[0].strip().strip(\"'\"),port_type,data[2].strip().strip(\"'\"),data[3].strip().strip(\"'\")\n",
    "                 ,data[4].strip().strip(\"'\"),data[5].strip().strip(\"'\")]\n",
    "    conn.execute(\"\"\"insert into port values(?,?,?,?,?,?)\"\"\", ins_query)\n",
    "    conn.commit()\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### function extracting the input ports\n",
    "\n",
    "def input_ports(line):\n",
    "    #print(\"Extracting Input ports.\")\n",
    "    \n",
    "    ## Extract data between \"(\" and \")\".\n",
    "    ## % FACT: has_in_port(step_id, port_id).\n",
    "\n",
    "    data = line[line.index(\"(\")+1:line.index(\")\")]\n",
    "    \n",
    "    data = data.split(',')\n",
    "    ins_query = [data[0].strip().strip(\"'\").strip('\"'),data[1].strip().strip(\"'\").strip('\"')]\n",
    "    conn.execute(\"\"\"insert into has_in_port values(?,?)\"\"\", ins_query)\n",
    "    conn.commit()\n",
    "    \n",
    "    #in_ports[data[0]].append((data[0].strip(), data[1].strip()))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### function extracting the output ports \n",
    "\n",
    "def output_ports(line): \n",
    "    #print(\"Extracting output ports.\")\n",
    "    ## Extract data between \"(\" and \")\".\n",
    "    data = line[line.index(\"(\")+1:line.index(\")\")]\n",
    "    data = data.split(',')\n",
    "    ins_query = [data[0].strip().strip(\"'\").strip('\"'),data[1].strip().strip(\"'\").strip('\"')]\n",
    "    conn.execute(\"\"\"insert into has_out_port values(?,?)\"\"\", ins_query)\n",
    "    conn.commit()\n",
    "    #out_ports[data[0]].append((data[0].strip(), data[1].strip()))\n",
    "    #print(data)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### function extracting the subprograms \n",
    "\n",
    "def has_subprogram(line): \n",
    "    #print(\"Extracting output ports.\")\n",
    "    ## Extract data between \"(\" and \")\".\n",
    "    data = line[line.index(\"(\")+1:line.index(\")\")]\n",
    "    data = data.split(',')\n",
    "    \n",
    "    ins_query = [data[0].strip().strip(\"'\").strip('\"'),data[1].strip().strip(\"'\").strip('\"')]\n",
    "    conn.execute(\"\"\"insert into has_subprogram values(?,?)\"\"\", ins_query)\n",
    "    conn.commit()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### function extracting the output ports \n",
    "\n",
    "def get_port_connects_to_channel(line): \n",
    "     \n",
    "    data = line[line.index(\"(\")+1 : line.index(\")\")]\n",
    "    data = data.split(',')\n",
    "\n",
    "    ins_query = [data[0].strip().strip(\"'\"),data[1].strip().strip(\"'\")]\n",
    "    conn.execute(\"\"\"insert into port_connects_to_channel values(?,?)\"\"\", ins_query)\n",
    "    conn.commit()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_inflow_connections(line): \n",
    "     \n",
    "    #print(line)\n",
    "    data = line[line.index(\"(\")+1:line.index(\")\")]\n",
    "    data = data.split(',')\n",
    "    #inflow_conn[data[0]]= data[1].strip()\n",
    "    \n",
    "    ins_query = [data[0].strip().strip(\"'\").strip('\"'),data[1].strip().strip(\"'\").strip('\"')]\n",
    "    conn.execute(\"\"\"insert into inflow_connects_to_channel values(?,?)\"\"\", ins_query)\n",
    "    conn.commit()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_outflow_connections(line): \n",
    "    #print(\"Extracting output ports.\")\n",
    "    ## Extract data between \"(\" and \")\".\n",
    "    data = line[line.index(\"(\")+1:line.index(\")\")]\n",
    "    data = data.split(',')\n",
    "    #outflow_conn[data[0]]= data[1].strip()\n",
    "\n",
    "    ins_query = [data[0].strip().strip(\"'\").strip('\"'),data[1].strip().strip(\"'\").strip('\"')]\n",
    "    conn.execute(\"\"\"insert into outflow_connects_to_channel values(?,?)\"\"\", ins_query)\n",
    "    conn.commit()\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### function extracting the output ports \n",
    "\n",
    "def get_port_data(line): \n",
    "    #print(\"Extracting output ports.\")\n",
    "    ## Extract data between \"(\" and \")\".\n",
    "    data = line[line.index(\"(\")+1:line.index(\")\")]\n",
    "    data = data.split(',')\n",
    "    \n",
    "    ins_query = [data[0].strip().strip(\"'\"),data[1].strip().strip(\"'\"),data[2].strip().strip(\"'\")]\n",
    "    conn.execute(\"\"\"insert into data values(?,?,?)\"\"\", ins_query)\n",
    "    conn.commit()\n",
    "    #print(data)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### function extracting the output ports \n",
    "\n",
    "def get_channel(line): \n",
    "    #print(\"Extracting output ports.\")\n",
    "    ## Extract data between \"(\" and \")\".\n",
    "    data = line[line.index(\"(\")+1:line.index(\")\")]\n",
    "    data = data.split(',')\n",
    "    \n",
    "    ins_query = [data[0].strip().strip(\"'\").strip('\"'),data[1].strip().strip(\"'\").strip('\"')]\n",
    "    conn.execute(\"\"\"insert into channel values(?,?)\"\"\", ins_query)\n",
    "    conn.commit()\n",
    "    #channel[data[0]]= data[1].strip()\n",
    "    #print(data)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### function extracting the port alias\n",
    "\n",
    "def port_alias(line):\n",
    "    data = line[line.index(\"(\")+1:line.index(\")\")]\n",
    "    data = data.split(',')\n",
    "    \n",
    "    port_id = data[0].strip()\n",
    "    alias = data[1].strip().strip(\"'\")\n",
    "    \n",
    "    #print(port_name, port_id,qualified_name)\n",
    "    \n",
    "    ins_query = [data[0].strip().strip(\"'\").strip('\"'),data[1].strip().strip(\"'\").strip('\"')]\n",
    "    conn.execute(\"\"\"insert into port_alias values(?,?)\"\"\", ins_query)\n",
    "    conn.commit()\n",
    "    \n",
    "    '''\n",
    "    ### regex for splitting the string and getting qualified program name\n",
    "    regex = re.compile(r'>|<')\n",
    "    qname = regex.split(qualified_name)\n",
    "    \n",
    "    pname = qname[0].split('.')[-1] \n",
    "    \n",
    "    if pname.find('-') > -1:\n",
    "        port_alt_name[alias] = pname[:-1]+ '/' +port_name\n",
    "    else:\n",
    "        port_alt_name[alias] = pname + '/' +port_name\n",
    "       \n",
    "    '''\n",
    "    return \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_yw_model(filename):\n",
    "    regex = re.compile(r'^%')\n",
    "    chk_channel = re.compile(r'^ch')\n",
    "    with open(filename, \"r\") as yw_struct:\n",
    "        line = yw_struct.readline()\n",
    "        while line:\n",
    "            #print(line)\n",
    "            comments = regex.match(line)\n",
    "            if comments: \n",
    "                #print(line)\n",
    "                line = yw_struct.readline()\n",
    "            else:  \n",
    "                if(\"program(\" in line and \"has_subprogram\" not in line):\n",
    "                    extract_steps(line)\n",
    "                elif(\"workflow(\" in line):\n",
    "                    extract_workflows(line)            \n",
    "                elif(\"has_subprogram(\" in line):\n",
    "                    has_subprogram(line)            \n",
    "                elif(\"port(\" in line  and \"has_in_port(\" not in line and \"has_out_port\" not in line):\n",
    "                #    print(line)\n",
    "                    extract_ports(line)\n",
    "                elif(\"has_in_port(\" in line):\n",
    "                    input_ports(line)\n",
    "                elif(\"has_out_port(\" in line ):\n",
    "                    output_ports(line)\n",
    "                elif (\"port_alias(\" in line ): \n",
    "                    port_alias(line)\n",
    "                elif(\"data(\" in line):\n",
    "                    get_port_data(line)\n",
    "                elif(\"port_connects_to_channel(\" in line):\n",
    "                    #print(line)\n",
    "                    get_port_connects_to_channel(line)\n",
    "                elif(\"inflow_connects_to_channel(\"in line):\n",
    "                    #print(line)\n",
    "                    get_inflow_connections(line)                    \n",
    "                elif(\"outflow_connects_to_channel(\"in line):\n",
    "                    get_outflow_connections(line)\n",
    "                elif( chk_channel.match(line) ):\n",
    "                    get_channel(line)\n",
    "\n",
    "                line = yw_struct.readline()\n",
    "        \n",
    "        #get_in_out_ports()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "no such table: wf_ports",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-ed6cb8cb0b90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m''' drop table workflow '''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m''' drop table cwl_steps_info '''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m''' drop table wf_ports '''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m''' drop table qual_portname '''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such table: wf_ports"
     ]
    }
   ],
   "source": [
    "conn.commit()\n",
    "conn.execute (''' drop table channel ''')                    \n",
    "conn.execute (''' drop table data  ''')                 \n",
    "conn.execute (''' drop table has_in_port ''')                  \n",
    "conn.execute (''' drop table has_out_port ''')                \n",
    "conn.execute (''' drop table has_subprogram ''')              \n",
    "conn.execute (''' drop table inflow_connects_to_channel ''')  \n",
    "conn.execute (''' drop table outflow_connects_to_channel ''')\n",
    "conn.execute (''' drop table port ''')\n",
    "conn.execute (''' drop table port_alias ''')\n",
    "conn.execute (''' drop table port_connects_to_channel ''')\n",
    "conn.execute (''' drop table steps ''')\n",
    "conn.execute (''' drop table workflow ''')\n",
    "conn.execute (''' drop table cwl_steps_info ''')\n",
    "conn.execute (''' drop table wf_ports ''')\n",
    "conn.execute (''' drop table qual_portname ''')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x10f0f4e30>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create tables for storing the data model. \n",
    "\n",
    "\n",
    "\n",
    "# % FACT: program(program_id, program_name, qualified_program_name, begin_annotation_id, end_annotation_id).\n",
    "conn.execute(\"\"\"create table steps (\n",
    "                program_id      int     primary key not NULL ,\n",
    "                program_name      text,\n",
    "                qualified_program_name  text)\n",
    "            \"\"\")\n",
    "\n",
    "#% FACT: workflow(program_id).\n",
    "\n",
    "conn.execute(\"\"\"create table workflow (\n",
    "                program_id      int     primary key not NULL\n",
    "                )\n",
    "            \"\"\")\n",
    "\n",
    "#% FACT: has_subprogram(program_id, subprogram_id).\n",
    "\n",
    "conn.execute(\"\"\"create table has_subprogram (\n",
    "                program_id  int,\n",
    "                sub_program_id      int\n",
    "                )\n",
    "            \"\"\")\n",
    "\n",
    "#% FACT: port(port_id, port_type, port_name, qualified_port_name, port_annotation_id, data_id).\n",
    "\n",
    "\n",
    "conn.execute(\"\"\"create table port (\n",
    "                port_id      int     primary key not NULL,\n",
    "                port_type  int,\n",
    "                port_name  text,\n",
    "                qualified_port_name text,\n",
    "                port_annotation_id int, \n",
    "                data_id int \n",
    "                )\n",
    "            \"\"\")\n",
    "\n",
    "\n",
    "\n",
    "# % FACT: port_alias(port_id, alias).\n",
    "\n",
    "conn.execute(\"\"\"create table port_alias (\n",
    "                port_id    int  ,\n",
    "                alias    text\n",
    "                )\n",
    "            \"\"\")\n",
    "\n",
    "#% FACT: has_in_port(block_id, port_id).\n",
    "\n",
    "conn.execute(\"\"\"create table has_in_port (\n",
    "                block_id int,\n",
    "                port_id    int\n",
    "                )\n",
    "            \"\"\")\n",
    "\n",
    "#% FACT: has_out_port(block_id, port_id).\n",
    "\n",
    "conn.execute(\"\"\"create table has_out_port (\n",
    "                block_id int,\n",
    "                port_id    int\n",
    "                )\n",
    "            \"\"\")\n",
    "\n",
    "#% FACT: data(data_id, data_name, qualified_data_name).\n",
    "\n",
    "conn.execute(\"\"\"create table data (\n",
    "                data_id int,\n",
    "                data_name    text,\n",
    "                qualified_data_name text\n",
    "                )\n",
    "            \"\"\")\n",
    "\n",
    "#% FACT: channel(channel_id, data_id).\n",
    "\n",
    "\n",
    "conn.execute(\"\"\"create table channel (\n",
    "                channel_id int,\n",
    "                data_id    int\n",
    "                )\n",
    "            \"\"\")\n",
    "\n",
    "#% FACT: port_connects_to_channel(port_id, channel_id).\n",
    "\n",
    "conn.execute(\"\"\"create table port_connects_to_channel (\n",
    "                port_id int,\n",
    "                channel_id    int\n",
    "                )\n",
    "            \"\"\")\n",
    "    \n",
    "# % FACT: inflow_connects_to_channel(port_id, channel_id).\n",
    "conn.execute(\"\"\"create table inflow_connects_to_channel (\n",
    "                port_id int,\n",
    "                channel_id    int\n",
    "                )\n",
    "            \"\"\")\n",
    "\n",
    "\n",
    "#% FACT: outflow_connects_to_channel(port_id, channel_id).\n",
    "conn.execute(\"\"\"create table outflow_connects_to_channel (\n",
    "                port_id int,\n",
    "                channel_id    int\n",
    "                )\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "read_yw_model(yw_model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql_steps_in_out_ports = '''\n",
    "select \n",
    "\twf.wf_id as workflow_id , s.program_id as program_id, s.program_name as program_name,\n",
    "\tp.port_name as port_name, p.port_id as port_id, p.port_type as port_type , p.data_id as data_id   \n",
    "from \n",
    "\tsteps s, port p, has_in_port inp, \n",
    "\t(select \n",
    "\t\tsub_program_id  , program_id as wf_id \n",
    "\t from \n",
    "\t\thas_subprogram\n",
    "\t) wf\n",
    "where \n",
    "\ts.program_id = inp.block_id\n",
    "and\tp.port_id = inp.port_id \n",
    "and inp.block_id  = wf.sub_program_id\n",
    "union \n",
    "select \n",
    "\twf.wf_id as workflow_id , s.program_id as program_id, s.program_name as program_name,\n",
    "\tp.port_name as port_name, p.port_id as port_id, p.port_type as port_type , p.data_id as data_id \n",
    "from \n",
    "\tsteps s, port p, has_out_port out,\n",
    "\t(select \n",
    "\t\tsub_program_id  , program_id as wf_id \n",
    "\t from \n",
    "\t\thas_subprogram\n",
    "\t) wf\n",
    "where \n",
    "\ts.program_id = out.block_id\n",
    "and\tp.port_id = out.port_id \n",
    "and out.block_id = wf.sub_program_id\n",
    "'''\n",
    "\n",
    "\n",
    "sql_wf_ports = '''\n",
    "select \n",
    "\ts.program_id, s.program_name, p.port_name, p.port_id, p.port_type, p.data_id  \n",
    "from \n",
    "\tsteps s, port p, has_in_port inp \n",
    "where \n",
    "\ts.program_id = inp.block_id\n",
    "and\tp.port_id = inp.port_id \n",
    "and inp.block_id in \n",
    "\t(select \n",
    "\t\tprogram_id  \n",
    "\t from \n",
    "\t\tworkflow\n",
    "\t)\n",
    "union \n",
    "select \n",
    "\ts.program_id, s.program_name, p.port_name,p.port_id, p.port_type , p.data_id\n",
    "from \n",
    "\tsteps s, port p, has_out_port out \n",
    "where \n",
    "\ts.program_id = out.block_id\n",
    "and\tp.port_id = out.port_id \n",
    "and out.block_id in \n",
    "\t(select \n",
    "\t\tprogram_id  \n",
    "\t from \n",
    "\t\tworkflow\n",
    "\t)\n",
    "'''\n",
    "\n",
    "sql_qual_portname = '''\n",
    "select \n",
    "\tdistinct p.program_id as workflow_id,  p.port_id,  p.program_name, p.port_name ,p.port_name as qualified_portname, p.port_type , p.data_id\n",
    "from\n",
    "\twf_ports p, inflow_connects_to_channel q\n",
    " where upper(p.port_type) in ('IN')\n",
    " and p.port_id = q.port_id\n",
    "union \n",
    "select\n",
    "\tp.workflow_id, p.port_id, p.program_name, p.port_name, p.program_name || '/' || p.port_name as qualified_portname, p.port_type , p.data_id\n",
    "from\n",
    "\tcwl_steps_info p\n",
    "where upper(p.port_type)= 'OUT'\n",
    "union\n",
    "select\n",
    "\tp.program_id as workflow_id, p.port_id, p.program_name, p.port_name, p.port_name as qualified_portname, p.port_type , p.data_id\n",
    "from\n",
    "\twf_ports p, port po\n",
    "where p.port_id = po.port_id \n",
    "and upper(po.port_name) like '_YW_IN%'\n",
    "'''\n",
    "\n",
    "sql_wf_qual_out_port = '''\n",
    "select \n",
    "\tp.program_name, q.port_name, p.program_name || '/' || p.port_name as qualified_portname, p.port_type , p.data_id\n",
    "from \n",
    "\tcwl_steps_info p , port q\n",
    "where q.port_id = p.port_id\n",
    "and p.port_id in \n",
    "\t(\n",
    "\tselect \n",
    "\t\tport_id\n",
    "\tfrom \n",
    "\t\tport_connects_to_channel\n",
    "\twhere \n",
    "\t\tchannel_id in \n",
    "\t\t(select \n",
    "\t\t\tmax(channel_id)\n",
    "\t\tfrom \n",
    "\t\t\toutflow_connects_to_channel\n",
    "\t\tgroup by port_id\n",
    "\t\t)\n",
    "\t)\n",
    "union \n",
    "select \n",
    "\tp.program_name, pa.alias as port_name, p.program_name || '/' || p.port_name as qualified_portname, p.port_type , p.data_id\n",
    "from \n",
    "\tcwl_steps_info p , port q, port_alias pa\n",
    "where q.port_id = p.port_id\n",
    "and p.port_id = pa.port_id\n",
    "and p.port_id in \n",
    "\t(\n",
    "\tselect \n",
    "\t\tport_id\n",
    "\tfrom \n",
    "\t\tport_connects_to_channel\n",
    "\twhere \n",
    "\t\tchannel_id in \n",
    "\t\t(select \n",
    "\t\t\tmax(channel_id)\n",
    "\t\tfrom \n",
    "\t\t\toutflow_connects_to_channel\n",
    "\t\tgroup by port_id\n",
    "\t\t)\n",
    "\t)\n",
    "union\n",
    "select \n",
    "\tp.qualified_port_name, p.port_name,  p.qualified_port_name, p.port_type , p.data_id\n",
    "from \n",
    "\tport p \n",
    "where p.port_name like '_YW_OUT%'\n",
    "'''\n",
    "\n",
    "sql_dangling_port_id = \"\"\"\n",
    "select \n",
    "\tport_id \n",
    "from\n",
    "\tport \n",
    "where data_id in \n",
    "(\n",
    "\tselect distinct data_id from port  \n",
    "\tEXCEPT\n",
    "\tselect distinct data_id  from channel\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "sql_port_alias = '''\n",
    "select \n",
    "    port_id, alias\n",
    "from \n",
    "    port_alias'''\n",
    "\n",
    "#df_dangling_ports = pd.read_sql_query(sql_dangling_port_id, con=conn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x10f1ae030>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.execute('create table cwl_steps_info as ' + sql_steps_in_out_ports)\n",
    "#conn.execute('create table wf_ports as ' + sql_wf_ports)\n",
    "#conn.execute('create table qual_portname as ' + sql_qual_portname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cwl_file_df = pd.DataFrame()\n",
    "wf_port_df = pd.DataFrame()\n",
    "qual_portname = pd.DataFrame()\n",
    "qual_wf_out_port = pd.DataFrame()\n",
    "df_dangling_ports = pd.DataFrame()\n",
    "df_port_alias = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwl_file_df = pd.read_sql_query(sql_steps_in_out_ports, con=conn)\n",
    "wf_port_df = pd.read_sql_query(sql_wf_ports, con=conn)\n",
    "df_dangling_ports = pd.read_sql_query(sql_dangling_port_id, con=conn)\n",
    "df_port_alias = pd.read_sql_query(sql_port_alias, con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Add an output port in the ports tables\n",
    "def ins_out_port(program_name):\n",
    "    wf_id = cwl_file_df[cwl_file_df['program_name'] == program_name]['workflow_id'].values[0]\n",
    "    prog_id = cwl_file_df[cwl_file_df['program_name'] == program_name]['program_id'].values[0]\n",
    "    port_id = cwl_file_df['port_id'].max() + 1\n",
    "    data_id = cwl_file_df['data_id'].max() + 1\n",
    "    #print(port_id, data_id)\n",
    "    port_type = 'OUT'\n",
    "    port_name = '_YW_OUT_'+ program_name\n",
    "    qual_prog_name = program_name + '/' + port_name\n",
    "    sql = \"\"\"\n",
    "    insert into port values (?,?,?,?,?,?)\n",
    "    \"\"\"\n",
    "    data = [int(port_id), port_type, port_name,qual_prog_name,port_id,int(data_id)]\n",
    "    conn.execute(sql,data)\n",
    "    \n",
    "    sql = \"\"\"\n",
    "    insert into has_out_port values (?,?)\n",
    "    \"\"\"\n",
    "    data = [int(wf_id),int(port_id)]\n",
    "    conn.execute(sql,data)\n",
    "    data = [int(prog_id),int(port_id)]\n",
    "    conn.execute(sql,data)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Add an output port in the ports tables\n",
    "def ins_link_wf_port(port_id, wf_id,port_type,program_name):\n",
    "    #print(port_id, data_id)\n",
    "    new_port_id = get_max_port_id() + 1\n",
    "    data_id = cwl_file_df[cwl_file_df['port_id'] == port_id]['data_id']\n",
    "    #print(type(new_port_id))\n",
    "    \n",
    "    port_name = cwl_file_df[cwl_file_df['port_id'] == port_id]['port_name'].values[0]\n",
    "    \n",
    "    print(port_name)\n",
    "    if port_type == 'OUT':\n",
    "        wf_port_name = '_YW_OUT_'+ port_name\n",
    "        qual_prog_name = program_name + '/' + port_name\n",
    "        sql_link = \"\"\"\n",
    "                   insert into has_out_port values (?,?)\n",
    "                   \"\"\"\n",
    "        values = [int(wf_id),int(new_port_id)]\n",
    "    else: \n",
    "        wf_port_name = '_YW_IN_'+ port_name\n",
    "        qual_prog_name =  wf_port_name\n",
    "        sql_link = \"\"\"\n",
    "                   insert into has_in_port values (?,?)\n",
    "                   \"\"\"   \n",
    "        values = [int(wf_id),int(new_port_id)]\n",
    "        \n",
    "    print(qual_prog_name)\n",
    "    sql = \"\"\"\n",
    "    insert into port values (?,?,?,?,?,?)\n",
    "    \"\"\"\n",
    "    \n",
    "    data = [int(new_port_id), port_type, wf_port_name,qual_prog_name,port_id,int(data_id)]\n",
    "    conn.execute(sql,data)\n",
    "    #print(data)\n",
    "    #print(values)\n",
    "    conn.execute(sql_link,values)\n",
    "    conn.commit()\n",
    "    \n",
    "    #rebuild_dataframes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_max_port_id():\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('''SELECT max(port_id) from port ''')\n",
    "    max_port_id = cur.fetchone()\n",
    "    \n",
    "    return int(max_port_id[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for the dangling ports and create \n",
    "## the respective ports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the list of the dangling port id's and pass into the DF. \n",
    "for idx in cwl_file_df[cwl_file_df['port_id'].isin(df_dangling_ports['port_id'])].index:\n",
    "    wf_id = cwl_file_df.loc[idx]['workflow_id']\n",
    "    port_id = cwl_file_df.loc[idx]['port_id']\n",
    "    port_type = cwl_file_df.loc[idx]['port_type']\n",
    "    program_name = cwl_file_df.loc[idx]['program_name']\n",
    "    ins_link_wf_port(port_id, wf_id,port_type,program_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check for the programs without output ports\n",
    "### use the ins_out_port to create the output port for wf and prog. \n",
    "\n",
    "program_name_uniq = cwl_file_df['program_name'].unique()\n",
    "program_with_out  = cwl_file_df[cwl_file_df['port_type'] == 'OUT'][\"program_name\"].unique()\n",
    "prog_wo_outport = list(set(program_name_uniq).difference(set(program_with_out)))\n",
    "\n",
    "for prog in prog_wo_outport:\n",
    "    #print(prog)\n",
    "    ins_out_port(prog)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reload the dataframes now \n",
    "\n",
    "conn.execute('create table wf_ports as ' + sql_wf_ports)\n",
    "conn.execute('create table qual_portname as ' + sql_qual_portname)\n",
    "\n",
    "cwl_file_df = pd.read_sql_query(sql_steps_in_out_ports, con=conn)\n",
    "wf_port_df = pd.read_sql_query(sql_wf_ports, con=conn)\n",
    "qual_portname = pd.read_sql_query(sql_qual_portname, con=conn)\n",
    "qual_wf_out_port = pd.read_sql_query(sql_wf_qual_out_port, con=conn)\n",
    "df_dangling_ports = pd.read_sql_query(sql_dangling_port_id, con=conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_filename(program_id, is_wf):\n",
    "    wfid_list = wf_port_df['program_id'].unique()\n",
    "    if is_wf:\n",
    "        program_name =wf_port_df[wf_port_df['program_id'] ==program_id]['program_name'].values[0]\n",
    "        return 'wf_' + program_name + '.cwl'\n",
    "    elif program_id in wfid_list:      \n",
    "        program_name = cwl_file_df[cwl_file_df['program_id'] ==program_id]['program_name'].values[0]\n",
    "        return 'wf' + program_name + '.cwl'\n",
    "    else:\n",
    "        program_name = cwl_file_df[cwl_file_df['program_id'] ==program_id]['program_name'].values[0]\n",
    "        return program_name + '.cwl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_cwl_file(filename, header, input_params, output_params):\n",
    "    #print(filename)\n",
    "    with open(filename,'w+') as writer: \n",
    "        writer.write(header)\n",
    "        writer.write(input_params)\n",
    "        writer.write(output_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wf_steps(workflow_id):\n",
    "    header_step = \"steps: \\n \"\n",
    "    buffer=''\n",
    "    prog_list = cwl_file_df[cwl_file_df['workflow_id'] == workflow_id]['program_id'].unique()\n",
    "    \n",
    "    for prog in prog_list: \n",
    "        outport_list= []\n",
    "        prog_name = cwl_file_df[cwl_file_df['program_id'] ==prog]['program_name'].values[0]\n",
    "        filename = get_filename(prog,False)\n",
    "        \n",
    "        buffer = buffer + prog_name + ': \\n ' + ' run: ' +filename + ' \\n ' + ' in: \\n'\n",
    "        \n",
    "        for pid in cwl_file_df[cwl_file_df[\"program_id\"]==prog].index:\n",
    "            \n",
    "            port_id = cwl_file_df.loc[pid]['port_id'] \n",
    "            port_name = cwl_file_df.loc[pid]['port_name'] \n",
    "            port_type = cwl_file_df.loc[pid]['port_type']       \n",
    "            data_id = cwl_file_df.loc[pid]['data_id']\n",
    "            \n",
    "            if port_type == 'IN':\n",
    "                \n",
    "                filtered_df =  qual_portname[qual_portname[\"workflow_id\"] == workflow_id]\n",
    "                qn_df = filtered_df[filtered_df[\"data_id\"] == data_id][\"qualified_portname\"]\n",
    "                if len(qn_df) == 0 :\n",
    "                    alias = df_port_alias[df_port_alias[\"port_id\"]==port_id]['alias']\n",
    "                    if len(alias) != 0 :\n",
    "                        qname = alias.values[0]\n",
    "                    else:\n",
    "                        qname = port_name\n",
    "                else: \n",
    "                    qname = qn_df.values[0]\n",
    "                buffer = buffer + '   ' + port_name + ': ' + qname + '\\n'\n",
    "            else: \n",
    "                outport_list.append(port_name)\n",
    "            #break\n",
    "        buffer = buffer + \"  out: [\" + ','.join(outport_list) + '] \\n '    \n",
    "    \n",
    "    return header_step + buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps: \n",
      " \"initialize_run\": \n",
      "  run: \"initialize_run\".cwl \n",
      "  in: \n",
      "   \"cassette_id\": \"cassette_id\"\n",
      "   \"sample_score_cutoff\": \"sample_score_cutoff\"\n",
      "  out: [\"run_log\"] \n",
      " \"load_screening_results\": \n",
      "  run: \"load_screening_results\".cwl \n",
      "  in: \n",
      "   \"cassette_id\": \"cassette_id\"\n",
      "   \"sample_spreadsheet\": \"sample_spreadsheet\"\n",
      "  out: [\"run_log\",\"sample_name\",\"sample_quality\"] \n",
      " \"calculate_strategy\": \n",
      "  run: \"calculate_strategy\".cwl \n",
      "  in: \n",
      "   \"data_redundancy\": \"data_redundancy\"\n",
      "   \"sample_name\": \"load_screening_results\"/\"sample_name\"\n",
      "   \"sample_quality\": \"load_screening_results\"/\"sample_quality\"\n",
      "   \"sample_score_cutoff\": \"sample_score_cutoff\"\n",
      "  out: [\"accepted_sample\",\"energies\",\"num_images\",\"rejected_sample\"] \n",
      " \"log_rejected_sample\": \n",
      "  run: \"log_rejected_sample\".cwl \n",
      "  in: \n",
      "   \"cassette_id\": \"cassette_id\"\n",
      "   \"rejected_sample\": \"calculate_strategy\"/\"rejected_sample\"\n",
      "  out: [\"rejection_log\"] \n",
      " \"collect_data_set\": \n",
      "  run: \"collect_data_set\".cwl \n",
      "  in: \n",
      "   \"accepted_sample\": \"calculate_strategy\"/\"accepted_sample\"\n",
      "   \"cassette_id\": \"cassette_id\"\n",
      "   \"energies\": \"calculate_strategy\"/\"energies\"\n",
      "   \"num_images\": \"calculate_strategy\"/\"num_images\"\n",
      "  out: [\"energy\",\"frame_number\",\"raw_image_path\",\"run_log\",\"sample_id\"] \n",
      " \"transform_images\": \n",
      "  run: \"transform_images\".cwl \n",
      "  in: \n",
      "   \"calibration_image\": \"calibration_image\"\n",
      "   \"energy\": \"collect_data_set\"/\"energy\"\n",
      "   \"frame_number\": \"collect_data_set\"/\"frame_number\"\n",
      "   \"raw_image_path\": \"collect_data_set\"/\"raw_image_path\"\n",
      "   \"sample_id\": \"collect_data_set\"/\"sample_id\"\n",
      "  out: [\"corrected_image\",\"corrected_image_path\",\"pixel_count\",\"run_log\",\"total_intensity\"] \n",
      " \"log_average_image_intensity\": \n",
      "  run: \"log_average_image_intensity\".cwl \n",
      "  in: \n",
      "   \"cassette_id\": \"cassette_id\"\n",
      "   \"corrected_image_path\": \"transform_images\"/\"corrected_image_path\"\n",
      "   \"frame_number\": \"collect_data_set\"/\"frame_number\"\n",
      "   \"pixel_count\": \"transform_images\"/\"pixel_count\"\n",
      "   \"sample_id\": \"collect_data_set\"/\"sample_id\"\n",
      "   \"total_intensity\": \"transform_images\"/\"total_intensity\"\n",
      "  out: [\"collection_log\"] \n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(get_wf_steps(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## creating the cwl files and the wf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_sql/\"simulate_data_collection\"\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "cur = conn.cursor()\n",
    "cur.execute(''' select program_id from workflow order by 1 desc''')\n",
    "\"\"\"\n",
    "\n",
    "wf_id = cwl_file_df['workflow_id'].unique()\n",
    "prog_list = cwl_file_df['program_id'].unique()\n",
    "dirname = 'example_sql/' + wf_port_df[wf_port_df[\"program_id\"] ==1]['program_name'].values[0]\n",
    "\n",
    "print(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'example_sql/\"simulate_data_collection\"/\"initialize_run\".cwl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-8109194c9d5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0moutput_buffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_buffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"baseCommand: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mwrite_cwl_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwl_file_header\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-98d9a464eef2>\u001b[0m in \u001b[0;36mwrite_cwl_file\u001b[0;34m(filename, header, input_params, output_params)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwrite_cwl_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#print(filename)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'example_sql/\"simulate_data_collection\"/\"initialize_run\".cwl'"
     ]
    }
   ],
   "source": [
    "for prog_id in prog_list: \n",
    "\n",
    "    cwl_file_header = '''\n",
    "#!/usr/bin/env cwl-runner\n",
    "cwlVersion: v1.0\n",
    "class: CommandLineTool\n",
    "'''\n",
    "    input_buffer = 'inputs: \\n'\n",
    "    output_buffer = 'outputs: \\n'\n",
    "    \n",
    "    pname = cwl_file_df[cwl_file_df[\"program_id\"] == [prog_id]]['program_name'].values[0]\n",
    "    #print(prog_id)\n",
    "    filename = dirname + '/' + get_filename(prog_id, False)\n",
    "\n",
    "    #print(filename)\n",
    "    for p_idx in cwl_file_df[cwl_file_df[\"program_id\"] == [prog_id]].index:\n",
    "        #pname = cwl_file_df.loc[p_idx]['program_name']\n",
    "        pid = cwl_file_df.loc[p_idx]['program_id']\n",
    "        #print(pname)\n",
    "        port_name = cwl_file_df.loc[p_idx]['port_name'] \n",
    "        port_type = cwl_file_df.loc[p_idx]['port_type'] \n",
    "        #print(port_name, port_type)\n",
    "\n",
    "        if port_type == 'IN':\n",
    "            input_buffer = input_buffer + ' '+ port_name + ': \\n'+ '  type: string \\n \\n'\n",
    "            #print(input_buffer)\n",
    "        else: \n",
    "            output_buffer = output_buffer + ' '+ port_name + ': \\n'+ '  type: string \\n \\n'\n",
    "            #print(output_buffer)\n",
    "    \n",
    "    output_buffer = output_buffer + \"baseCommand: \"\n",
    "    write_cwl_file(filename, cwl_file_header, input_buffer, output_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwl_wf_header = '''\n",
    "#!/usr/bin/env cwl-runner\n",
    "cwlVersion: v1.0\n",
    "class: Workflow\n",
    "requirements:\n",
    "    - class: SubworkflowFeatureRequirement\n",
    "\n",
    "'''\n",
    "workflow_list = wf_port_df['program_id'].unique()\n",
    "\n",
    "for id in sorted(workflow_list, reverse=True):\n",
    "    input_buffer = 'inputs: \\n'\n",
    "    output_buffer = 'outputs: \\n'\n",
    "    #print(id)\n",
    "    wf_name = wf_port_df[wf_port_df['program_id']== id][\"program_name\"].values[0]\n",
    "    filename= dirname +'/' + get_filename(id, True)\n",
    "    #print(filename)\n",
    "    for p_id in wf_port_df[wf_port_df['program_id']== id].index:\n",
    "        prog_id = wf_port_df.loc[p_id]['program_id']\n",
    "        #print(int(prog_id))\n",
    "\n",
    "\n",
    "        pname = wf_port_df.loc[p_id]['program_name']\n",
    "        port_name = wf_port_df.loc[p_id]['port_name'] \n",
    "        port_type = wf_port_df.loc[p_id]['port_type'] \n",
    "\n",
    "\n",
    "        if port_type == 'IN':\n",
    "            input_buffer = input_buffer + ' '+ port_name + ': \\n'+ '  type: string \\n \\n'\n",
    "            #print(input_buffer)\n",
    "        else: \n",
    "            qname = qual_wf_out_port[qual_wf_out_port['port_name'] == port_name]['qualified_portname'].values[0]\n",
    "            output_buffer = output_buffer + '  ' +  port_name  + ': \\n' + '   type: string \\n   outputSource: '+ qname +'\\n'\n",
    "            #print(output_buffer)\n",
    "    \n",
    "    wf_step_contents = get_wf_steps(id)\n",
    "    write_cwl_file(filename,cwl_wf_header + input_buffer, output_buffer, wf_step_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual_portname[qual_portname['data_id'] ==13]['workflow_id'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual_portname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwl_file_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual_wf_out_port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual_portname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
